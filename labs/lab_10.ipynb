{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Goal. \n",
    "The goal of this lab is to investigate two examples of Competitive Co-Evolution: the first one dealing with a robotic prey-predator experiment, the second one dealing with a computational model for sorting algorithms, named Sorting Network.\n",
    "## Getting started. \n",
    "This lab continues the use of the inspyred framework for the Python programming language seen in the previous labs. If you did not participate in the previous labs, you may want to look those over first and then start this lab's exercises. Additionally, in this lab we will use a custom 2-D robotic simulator (for more details, see module 9's exercises), and another Python library for Evolutionary Computation named deap $^{[1]}$. With respect to inspyred, deap has some nice features such as a simple template for co-evolutionary algorithms, and an easy-to-use Genetic Programming implementation. We will see the latter in the next lab.\n",
    "\n",
    "Note once again that, unless otherwise specified, in this module's exercises we will use real-valued genotypes and that the aim of the algorithms will be to minimize the fitness function f(x), i.e. lower values correspond to a better fitness!\n",
    "\n",
    "----\n",
    "[1]: Distributed Evolutionary Algorithms in Python: https://github.com/DEAP/deap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 1\n",
    "In this exercise we will replicate the prey-predator competitive co-evolution experiments we have seen during the lecture. To do so, we will use a custom 2-D simulator. In this case by default the simulator generates an \"empty\" (without obstacles) arena $1920 \\times 1080$ px, with two cars that at the beginning of the simulation are placed at opposite corners of the arena. One robot has the role of a \"prey\" (blue), the other acts as a \"predator\" (red). The goal of the prey is to avoid being \"captured\" (i.e., get in contact with) the predator, whereas the goal of the predator is to \"capture\" (get in touch with) the prey. \n",
    "\n",
    "By default, both cars are controlled by a Feed Forward Neural Network (FFNN) with 4 lidar sensor inputs to detect walls, 2 inputs for distance and bearing towards the \"target\" -in this case towards the other robot-, 5 hidden nodes, and 5 output nodes for controlling the behaviour of the robot (for more details, see module 9's exercises). All nodes use a tanh activation function, with inputs/outputs normalized in $[0, 1]$ and weights evolved in the range $[−3, 3]$.\n",
    "\n",
    "In order to co-evolve the cars behaviors, two separate populations of preys and predators are evolved synchronously by two Evolutionary Algorithms that run in separate alternating threads (i.e., the evaluation part of the algorithm alternates between the two threads: evaluate preys, evaluate predators, evaluate preys, ...). Both algorithms can be parametrized differently (but, by default they use the same parameters), and are configured to keep an archive of best solutions (i.e., FFNN controllers) found during the evolution.\n",
    "\n",
    "At each generation, each algorithm simulates its own solutions in the current population against (a subset of) the solutions taken from the archive kept by the other algorithm. For efficiency purposes, the simulation takes as input a list of $numRobots$ candidate solutions that is split in two halves, the first one containing preys, the second one containing predators. Then the simulator lets each $i$-th robot (a prey), for $i$ in $[0,numRobots/2)$, \"compete\" against the $(i+numRobots/2)$-th robot (the corresponding predator). Therefore each prey and each predator can be repeated in the list multiple times, in order to generate all the needed pairwise competitions between preys and predators. Before starting the experiments, spend some time to have look at the script `utils/utils_10/robot_coevolution.py` and understand its main steps (in particular, see the method evaluator of the class `RobotEvaluator`).\n",
    "\n",
    "Depending on how fitness is defined for both preys and predators (you can change it in the next cell), different robot behaviors can be obtained. For each robot, the simulator returns three main quantities that can be used/combined differently to drive the co-evolution in different ways, namely:\n",
    "\n",
    "1. finalDistanceToTarget: the final (measured at the end of the simulation) distance to the \"target\" robot.\n",
    "2. minDistanceToTarget: the minimum (measured during the simulation) distance to the \"target\" robot.\n",
    "3. timeToContact: the time to contact (in timesteps, in the range [0,nrTimeStepsGen]).\n",
    "    \n",
    "By default, the preys are evolved to maximize their minDistanceToTarget, while the predators are evolved to minimize it. Please note that the two distance metrics range in $[0, \\sqrt{2}]$ (in px) where $\\sqrt{2}$ is pre-computed as the maximum distance normalized in the given environment (length of the diagonal of the arena). Also, note that, due to the aforementioned structure of the list of candidate solutions taken as input, preys are kept in the first $numRobots/2$ elements of the list, while predators are kept in the remaining elements, such that different fitness functions can be used for preys and predators.\n",
    "\n",
    "Furthermore, the way the two algorithms update the corresponding archives of best solutions can be controlled by the following parameters:\n",
    "\n",
    "- numOpponents: the number of opponents against which each robot competes at each generation (default: 1).\n",
    "- archiveType: the way competition with individuals from the archive is performed; possible values are {GENERATION, HALLOFFAME, BEST} (default: BEST). When GENERATION is selected, generational competition is performed, i.e. each algorithm keeps an archive containing one best solution for each of the previous numOpponents generations, such that at each generation each robot competes against the best opponents from those numOpponents generations (Master Tournaments). Similarly, when HALLOFFAME is selected each algorithm keeps an archive containing one best solution for each of the previous generations, however in this case there is no limit on the number of solutions kept in the archive (whose size increases along generations), and numOpponents indicates the number of solutions which are randomly sampled from the archive to perform pairwise competitions (see the lecture slides). When BEST is selected, a greedy approach is taken: in thisase indeed each algorithm keeps in the archive the best numOpponents opponents from all previous generations (not necessarily one per generation), and each robot competes against those opponents.\n",
    "- archiveUpdate: the way fitness is aggregated for each robot; possible values are {WORST, AVERAGE} (default: WORST). When WORST is selected, each robot competes against numOpponents opponents from the other algorithm's archive and its final fitness is set to its worst value obtained across numOpponents competitions (worst-case scenario). When AVERAGE is selected, the final fitness of each robot is set to its average value obtained across numOpponents competitions.\n",
    "- updateBothArchives: the way archives are updated at each generation; possible values are {True, False} (default: False). When False is selected, each algorithm updates only its own archive. When True is selected, each algorithm also recomputes the fitness of the opponents and updates the other algorithm's archive if needed (this is a non-standard feature).\n",
    "    \n",
    "Consider the following experiments:\n",
    "- Try out different parameter combinations of numOpponents, archiveType, archiveUpdate, and updateBothArchives, and observe what kind of robot behavior is evolved. Can you find cases where the prey \"wins\"? Can you find cases where the predator \"wins\"?\n",
    "- Try to change the fitness formulation and observe what kind of behavior is evolved. Remember to change the two flags problemPreysMaximize and problemPredatorsMaximize properly, according to the way you defined the fitness function.\n",
    "- (Optional) Try to change the EA's and FFNN's parameters to see if/how results change depending on those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "from utils.utils_10.inspyred_utils import NumpyRandomWrapper\n",
    "from utils.utils_10.exercise_maze import *\n",
    "from utils.utils_10.network import *\n",
    "from utils.utils_10.robots_coevolution import *\n",
    "import utils.utils_10.cfg as shared_variable\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"sensors\": True,\n",
    "    \"nrHiddenNodes\": 5,\n",
    "    \"nrHiddenLayers\": 1,\n",
    "    \"map\": \"white.png\",  # parameters for standard GA\n",
    "    \"popSize\": 10,  # population size\n",
    "    \"numGen\": 10,  # used with generation_termination\n",
    "    \"tournamentSize\": 2,  # tournament size (default 2)\n",
    "    \"mutationRate\": 0.2,  # mutation rate, per gene (default 0.1)\n",
    "    \"gaussianMean\": 0,  # mean of the Gaussian distribution used for mutation\n",
    "    \"gaussianStdev\": 0.1,  # std. dev. of the Gaussian distribution used for mutation\n",
    "    \"crossoverRate\": 1.0,  # rate at which crossover is performed (default 1.0)\n",
    "    \"numCrossoverPoints\": 1,  # number of crossover points used (default 1)\n",
    "    \"numElites\": 1,  # no. of elites (i.e. best individuals that are kept in the population # parameters for competitive coevolution\n",
    "    \"selectionSize\": 10,  # selection size (i.e. how many individuals are selected for reproduction)\n",
    "    \"numOpponents\": 1,  # number of opponents against which each robot competes at each generation\n",
    "    \"archiveType\": \"GENERATION\",  # possible types: {GENERATION,HALLOFFAME,BEST}\n",
    "    \"archiveUpdate\": \"AVERAGE\",  # possible types: {WORST,AVERAGE}\n",
    "    \"updateBothArchives\": True,  # True is each generation should update both archives, False otherwise\n",
    "    \"display\": True,\n",
    "    \"showArchives\": False,\n",
    "}\n",
    "\n",
    "config[\"selectionSize\"] = config[\"popSize\"]\n",
    "\n",
    "# 1. Generational competition: the archive is filled with the best individuals from previous n generations (e.g. n=5)\n",
    "# 2. Hall-of-Fame: each new individual is tested against *all best opponents* obtained so far.\n",
    "#    NOTE: Using this method, the no. of tournaments increases along generations!\n",
    "#    However, it is sufficient to test new individuals only against a limited sample of n opponents (e.g. n=10)\n",
    "# 3. Best competition: the archive is filled with the best n (e.g. n=5) individuals from *all* previous generations\n",
    "\n",
    "\n",
    "def fitness_eval_prey(\n",
    "    finalDistanceToTarget,\n",
    "    avgDistanceToTarget,\n",
    "    minDistanceToTarget,\n",
    "    maxDistanceToTarget,\n",
    "    timeToContact,\n",
    "):\n",
    "    fitness = finalDistanceToTarget\n",
    "    return fitness\n",
    "\n",
    "\n",
    "def fitness_eval_predator(\n",
    "    finalDistanceToTarget,\n",
    "    avgDistanceToTarget,\n",
    "    minDistanceToTarget,\n",
    "    maxDistanceToTarget,\n",
    "    timeToContact,\n",
    "):\n",
    "    fitness = finalDistanceToTarget\n",
    "    return fitness\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "cc = shared_variable.cfgs()\n",
    "\n",
    "# These two archives keep the best preys and best predators\n",
    "\n",
    "if config[\"archiveType\"] == \"GENERATION\" or config[\"archiveType\"] == \"BEST\":\n",
    "    cc.archivePreys = ArchiveSolutions(config[\"numOpponents\"])\n",
    "    cc.archivePredators = ArchiveSolutions(config[\"numOpponents\"])\n",
    "elif config[\"archiveType\"] == \"HALLOFFAME\":\n",
    "    cc.archivePreys = ArchiveSolutions()\n",
    "    cc.archivePredators = ArchiveSolutions()\n",
    "\n",
    "#  the initial popolations (we need to make initialize them externally to initialize the archives)\n",
    "\n",
    "cc.initialPreys = ArchiveSolutions(config[\"popSize\"])\n",
    "cc.initialPredators = ArchiveSolutions(config[\"popSize\"])\n",
    "\n",
    "# TODO: change maximize flag depending on how fitness is defined\n",
    "cc.problemPreysMaximize = (\n",
    "    True  # e.g. maximize (final/min) distance from predator or maximize time-to-contact\n",
    ")\n",
    "cc.problemPredatorsMaximize = (\n",
    "    False  # e.g. minimize (final/min) distance from prey or minimize time-to-contact\n",
    ")\n",
    "\n",
    "config[\"shared_variables\"] = cc\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "seed = 0\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "#  the following queues allow the two threads to alternate their execution\n",
    "qAB = Queue()\n",
    "qBA = Queue()\n",
    "\n",
    "# create the robot evaluator instances\n",
    "problemPreys = RobotEvaluator(\n",
    "    config,\n",
    "    fitness_eval_prey,\n",
    "    fitness_eval_predator,\n",
    "    \"Preys\",\n",
    "    qAB,\n",
    "    qBA,\n",
    "    seed,\n",
    "    cc.problemPreysMaximize,\n",
    ")\n",
    "problemPredators = RobotEvaluator(\n",
    "    config,\n",
    "    fitness_eval_predator,\n",
    "    fitness_eval_predator,\n",
    "    \"Predators\",\n",
    "    qBA,\n",
    "    qAB,\n",
    "    seed,\n",
    "    cc.problemPredatorsMaximize,\n",
    ")\n",
    "\n",
    "# create the initial populations\n",
    "for i in np.arange(config[\"popSize\"]):\n",
    "    candidatePrey = [\n",
    "        (problemPreys.geneMax - problemPreys.geneMin) * rng.random_sample()\n",
    "        + problemPreys.geneMin\n",
    "        for _ in range(problemPreys.nrWeights)\n",
    "    ]\n",
    "    cc.initialPreys.appendToArchive(candidatePrey)\n",
    "for i in np.arange(config[\"popSize\"]):\n",
    "    candidatePredator = [\n",
    "        (problemPredators.geneMax - problemPredators.geneMin) * rng.random_sample()\n",
    "        + problemPredators.geneMin\n",
    "        for _ in range(problemPredators.nrWeights)\n",
    "    ]\n",
    "    cc.initialPredators.appendToArchive(candidatePredator)\n",
    "\n",
    "t1 = threading.Thread(target=runEA, args=(problemPreys, config[\"display\"], rng, config))\n",
    "t2 = threading.Thread(\n",
    "    target=runEA, args=(problemPredators, config[\"display\"], rng, config)\n",
    ")\n",
    "\n",
    "# this is needed to unlock the thread \"Preys\" first\n",
    "qAB.put(1)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "if config[\"display\"]:\n",
    "    \"\"\"\n",
    "    # rerun every prey in the archive against every predator in the archive\n",
    "    preysPredators = []\n",
    "\n",
    "    # append preys\n",
    "    for predator in archivePredators.candidates:\n",
    "        for prey in archivePreys.candidates:\n",
    "            preysPredators.append(prey)\n",
    "    # append predators\n",
    "    for predator in archivePredators.candidates:\n",
    "        for prey in archivePreys.candidates:\n",
    "            preysPredators.append(predator)\n",
    "    \"\"\"\n",
    "\n",
    "    # rerun the best prey in the archive against the best predator in the archive\n",
    "    preysPredators = []\n",
    "    indexOfBestPrey = getIndexOfBest(cc.archivePreys.fitnesses, cc.problemPreysMaximize)\n",
    "    bestPrey = cc.archivePreys.candidates[indexOfBestPrey]\n",
    "    bestPreyFitness = cc.archivePreys.fitnesses[indexOfBestPrey]\n",
    "    indexOfBestPredator = getIndexOfBest(\n",
    "        cc.archivePredators.fitnesses, cc.problemPredatorsMaximize\n",
    "    )\n",
    "    bestPredator = cc.archivePredators.candidates[indexOfBestPredator]\n",
    "    bestPredatorFitness = cc.archivePredators.fitnesses[indexOfBestPredator]\n",
    "    print(\"prey \" + str(bestPreyFitness))\n",
    "    print(\"predator \" + str(bestPredatorFitness))\n",
    "    preysPredators.append(bestPrey)\n",
    "    preysPredators.append(bestPredator)\n",
    "\n",
    "    statsPreys = np.transpose(np.loadtxt(open(\"./stats_Preys.csv\", \"r\"), delimiter=\",\"))\n",
    "    statsPredators = np.transpose(\n",
    "        np.loadtxt(open(\"./stats_Predators.csv\", \"r\"), delimiter=\",\")\n",
    "    )\n",
    "\n",
    "    # plot fitness trends of preys and predators\n",
    "    figure(\"Preys\")\n",
    "    plot(statsPreys[2], label=\"Worst\")\n",
    "    plot(statsPreys[3], label=\"Best\")\n",
    "    plot(statsPreys[4], label=\"Median\")\n",
    "    plot(statsPreys[5], label=\"Mean\")\n",
    "    # yscale(\"log\")\n",
    "    xlabel(\"Generation\")\n",
    "    ylabel(\"Fitness\")\n",
    "    legend()\n",
    "\n",
    "    figure(\"Predators\")\n",
    "    plot(statsPredators[2], label=\"Worst\")\n",
    "    plot(statsPredators[3], label=\"Best\")\n",
    "    plot(statsPredators[4], label=\"Median\")\n",
    "    plot(statsPredators[5], label=\"Mean\")\n",
    "    # yscale(\"log\")\n",
    "    xlabel(\"Generation\")\n",
    "    ylabel(\"Fitness\")\n",
    "    legend()\n",
    "    show()\n",
    "    with open(\"results/bests.pkl\", \"wb\") as f:\n",
    "        pickle.dump([(bestPrey, bestPredator), config], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# NOTE: check that you are calling the correct version of python here!\n",
    "os.popen(\"python3 post_eval.py results/bests.pkl\").read();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "In this exercise we will use a competitive co-evolutionary approach for evolving a Sorting Network (SN)$^{[1]}$. A SN is an abstract mathematical model of a network of wires and comparator modules (connectors) that is used to sort a sequence of numbers fed as input to the network. Each comparator connects two wires and sorts the values by outputting the smaller value to one wire, and the larger value to the other. For further details on the theory behind SNs, refer to the  corresponding Wikipedia page. For illustration purposes, an example of SN is shown in the figure.\n",
    "\n",
    "![sn.png](img/img_10/sn.png)\n",
    "\n",
    "The code of this exercise is based on one of the deap examples and provides a nice template for a generic competitive co-evolutionary algorithm in this framework. Similarly to the previous exercise, also in this case two separate populations are kept, one for hosts (where each host is a candidate sorting network) and one for parasites (where each parasite is an array of a given number of shuffled sequences to be sorted). For simplicity, we consider here a binary sorting problem, where input sequences are (unsorted) binary strings of fixed size, such as $\\{1,0,0,0,1,1,0,1\\}$. The size of the evolved SNs (also called depth, i.e. its number of connectors) is instead variable and evolves with the hosts$^{[2]}$. The goal of a host is to sort all sequences in the competing parasite, while the goal of a parasite is to induce errors in the competing host. The fitness of a host is therefore calculated as the total number of sequences that it could not sort properly, from those\n",
    "sequences present in the parasite against which that host competed. The fitness of the parasite is exactly the same value. Obviously, the fitness of hosts (number of sorting errors) must be minimized, while the fitness of parasites should be maximized.\n",
    "\n",
    "While the deap library is based on some different concepts and implementation details with respect to the inspyred library we have used so far, its working principles are quite straightforward and can be understood rather easily. Take some time to have a look at the source code in the cell below and in the script `exercise_sortingnetwork.py` (note however that the implementation of the Sorting Network is available in the module `sortingnetwork.py` in the `utils/deapCoev folder`). The relevant parameters of the Evolutionary Algorithm, hosts and parasites, can be found at the beginning of the script. In particular, consider the parameters `INPUTS, POP_SIZE_HOSTS, POP_SIZE_PARASITES, HOF_SIZE, MAXGEN, H_CXPB, H_MUTPB, P_CXPB, P_MUTPB, H_TRNMT_SIZE, P_TRNMT_SIZE, P_NUM_SEQ`. Note that in this case (differently from the previous exercise) the two populations are evolved within a single thread, and that at each generation all hosts in the current population are tested against all parasites in the current population. A Hall-of-Fame is kept to store the SNs displaying the best performance across generations, and updated whenever a new SN has a better performance (smaller number of sorting errors) than the worst SN in the Hall-of-Fame. The final output of the script is a graphical representation of the best SN in the Hall-of-Fame, and the number of\n",
    "sorting errors it suffers on all possible input sequences of fixed input size equal to `INPUTS`. Also, the usual plot with the min/max/avg fitness trends is provided.\n",
    "\n",
    "Run the cell below to perform the competitive co-evolutionary experiment. Also in this case you can pass as argument to the script a specific seed.\n",
    "\n",
    " - Is the co-evolutionary algorithm able to evolve an optimal (without sorting errors) SN, in the default configuration?\n",
    " - Try to investigate this problem in different configurations. In particular, focus on the effect of the size of the input sequences (`INPUTS`), the number of input sequences per parasite (`P_NUM_SEQ`), and the two population sizes (`POP_SIZE_HOSTS` and` POP_SIZE_PARASITES`). If needed, also change the size of the Hall-of-Fame (`HOF_SIZE`) and the number of generations  (`MAXGEN`). What conclusions can you draw? For instance: What makes the problem harder? What is the effect of `P_NUM_SEQ`? What can you do to solve the harder problem instances?\n",
    " \n",
    "---\n",
    "\n",
    "[3]: Link to https://en.wikipedia.org/wiki/Sorting_network\n",
    "\n",
    "[4]: Note that the depth of a SN is a measure of its algorithmic complexity. Optimal (minimum-depth) SNs are currently known only up to a inputs sequences of size equal to 17, see the corresponding Wikipedia page. In principle, one could use EAs also for minimizing the depth, together with the sorting errors, either based on a single objective (with calarization) or on a multi-objective approach optimizing depth and sorting errors separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#    This file is part of DEAP.\n",
    "#\n",
    "#    DEAP is free software: you can redistribute it and/or modify\n",
    "#    it under the terms of the GNU Lesser General Public License as\n",
    "#    published by the Free Software Foundation, either version 3 of\n",
    "#    the License, or (at your option) any later version.\n",
    "#\n",
    "#    DEAP is distributed in the hope that it will be useful,\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n",
    "#    GNU Lesser General Public License for more details.\n",
    "#\n",
    "#    You should have received a copy of the GNU Lesser General Public\n",
    "#    License along with DEAP. If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "\n",
    "from utils.utils_10.deapCoev.sortingnetwork import *\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"INPUTS\": 5,  # length of the input sequence to sort\n",
    "    \"POP_SIZE_HOSTS\": 300,  # population size for hsots\n",
    "    \"POP_SIZE_PARASITES\": 300,  # population size for parasites\n",
    "    \"HOF_SIZE\": 1,  # size of the Hall-of-Fame\n",
    "    \"MAXGEN\": 50,  # number of generations\n",
    "    \"H_CXPB\": 0.5,  # crossover probability for hosts\n",
    "    \"H_MUTPB\": 0.3,  # mutation probability for hosts\n",
    "    \"P_CXPB\": 0.5,  # crossover probability for parasites\n",
    "    \"P_MUTPB\": 0.3,  # mutation probability for parasites\n",
    "    \"H_TRNMT_SIZE\": 3,  # tournament size for hosts\n",
    "    \"P_TRNMT_SIZE\": 3,  # tournament size for parasites\n",
    "    \"P_NUM_SEQ\": 20,  # number of shuffled sequences for each parasite\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# The EA parametrization\n",
    "\n",
    "# this four lines simply tells DEAP that\n",
    "# 1. hosts want to minimize (the sorting errors)\n",
    "# 2. parasites want to maximize (the sorting errors)\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Host\", list, fitness=creator.FitnessMin)\n",
    "creator.create(\"Parasite\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "htoolbox = base.Toolbox()\n",
    "ptoolbox = base.Toolbox()\n",
    "\n",
    "# register the initialization operators for hosts\n",
    "htoolbox.register(\n",
    "    \"network\",\n",
    "    genNetwork,\n",
    "    dimension=config[\"INPUTS\"],\n",
    "    min_size=config[\"INPUTS\"],\n",
    "    max_size=config[\"INPUTS\"] * 2,\n",
    ")\n",
    "htoolbox.register(\"individual\", tools.initIterate, creator.Host, htoolbox.network)\n",
    "htoolbox.register(\"population\", tools.initRepeat, list, htoolbox.individual)\n",
    "\n",
    "# register the initialization operators for parasites\n",
    "ptoolbox.register(\"parasite\", getParasite, dimension=config[\"INPUTS\"])\n",
    "# NOTE: each parasite is actually an array of P_NUM_SEQ shuffled sequences (not just one)\n",
    "ptoolbox.register(\n",
    "    \"individual\",\n",
    "    tools.initRepeat,\n",
    "    creator.Parasite,\n",
    "    ptoolbox.parasite,\n",
    "    config[\"P_NUM_SEQ\"],\n",
    ")\n",
    "ptoolbox.register(\"population\", tools.initRepeat, list, ptoolbox.individual)\n",
    "\n",
    "# register the evaluation/crossover/mutation/selection/clone operators for hosts\n",
    "# we keep the additional specific parameters as they are\n",
    "htoolbox.register(\"evaluate\", evalNetwork, dimension=config[\"INPUTS\"])\n",
    "htoolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "htoolbox.register(\n",
    "    \"mutate\",\n",
    "    mutNetwork,\n",
    "    dimension=config[\"INPUTS\"],\n",
    "    mutpb=0.2,\n",
    "    addpb=0.01,\n",
    "    delpb=0.01,\n",
    "    indpb=0.05,\n",
    ")\n",
    "htoolbox.register(\"select\", tools.selTournament, tournsize=config[\"H_TRNMT_SIZE\"])\n",
    "htoolbox.register(\"clone\", cloneHost)\n",
    "\n",
    "# register the crossover/mutation/selection/clone operators for parasites\n",
    "# note that in this case an evaluation function is not defined explicitly\n",
    "# (parasite\"s fitness is the same as the corresponding host, see below)\n",
    "# we keep the additional specific parameters as they are\n",
    "ptoolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "ptoolbox.register(\"indMutate\", tools.mutFlipBit, indpb=0.05)\n",
    "ptoolbox.register(\"mutate\", mutParasite, indmut=ptoolbox.indMutate, indpb=0.05)\n",
    "ptoolbox.register(\"select\", tools.selTournament, tournsize=config[\"P_TRNMT_SIZE\"])\n",
    "ptoolbox.register(\"clone\", cloneParasite)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "seed = 0\n",
    "main(seed, creator, htoolbox, ptoolbox, config);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
