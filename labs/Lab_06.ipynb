{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Goal\n",
    "The goal of this lab is to familiarize yourself with Particle Swarm Optimization and study the effect of parametrization on the algorithmic performance.\n",
    "\n",
    "Note once again that, unless otherwise specified, in this module's exercises we will use real-valued genotypes and that the aim of the algorithms will be to *minimize* the fitness function $f(\\mathbf{x})$, i.e. lower values correspond to a better fitness!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "As a first exercise, we will run a simple 2D Boids simulator, based on the Reynolds' flocking rules we have seen during the lectures. Although this exercise is not strictly related to PSO, it provides a good source of inspiration (and intuition) on how PSO works. \n",
    "\n",
    "The simulator allows you to change various aspects of the simulation, specifically the total number of boids, the number of neighbors whose information is collected by each boid (to determine cohesion, alignment, and separation), and the relative weights of each of the 3 flocking rules (behavior coefficients). Spend some time with the simulator, and try different simulation configurations.\n",
    "\n",
    "To help you figure out the behavior of the boids, you can find below the implementation of the `boid` class extracted from the source code of the simulator. In particular, check the `update` method.\n",
    "\n",
    "- What is the effect of each behavior coefficient?\n",
    "- Which combination of coefficients leads to the most ``natural'' flock behavior? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pygame\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "num_boids = 150  # advice: for graphical reasons avoid to use num_boids > 400\n",
    "separation = 0.2  # default: 0.8\n",
    "cohesion = 0.7  # default: 0.1\n",
    "alignment = 2  # default: 1.6\n",
    "\n",
    "\n",
    "# make sure you are calling the right version of python in the process below\n",
    "os.popen(\n",
    "    f\"python3 utils/utils_06/main.py {num_boids} {alignment} {cohesion} {separation}\"\n",
    ").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "In this exercise we will perform a comparative analysis of the results of Genetic Algorithm (as seen in Lab 2), Evolution Strategies (as seen in Lab 3) and Particle Swarm Optimization. \n",
    "The script will perform a single run of GA, ES and PSO, on one of the benchmark functions we have seen in the previous labs. As usual, the algorithm parametrization is shown in the code and can be easily modified.\n",
    "\n",
    "Questions:\n",
    "-  What kind of behavior does PSO have on different benchmark functions (change the parameter `args[\"problem_class\"]` to try at least a couple of functions), in comparison with the EAs? Does it show better or worse results? Does it converge faster or not?\n",
    "- What happens if you run the script multiple times? Do the various algorithms (and especially PSO) show consistent behavior?\n",
    "- Increase the problem dimensionality (`num_vars`, by default set to 2), e.g. to 10 or more. What do you observe in this case?\n",
    "-  Change the population size (by changing`args[\"pop_size\"]`, by default set to 50) and the number of generations (by changing `args[\"max_generations\"]`, by default set to 100), such that their product is fixed (e.g. $50 \\times 100$, $100 \\times 100$, etc.). Try two or three different combinations and observe the behavior of the three different algorithms. What do you observe in this case? Is it better to have smaller/larger populations or a smaller/larger number of generations? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pylab import *\n",
    "from inspyred import benchmarks\n",
    "\n",
    "\n",
    "from utils.utils_06.inspyred_utils import NumpyRandomWrapper\n",
    "import utils.utils_06.ga as ga\n",
    "import utils.utils_06.es as es\n",
    "import utils.utils_06.pso as pso\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "num_vars = 100  # Number of dimensions of the search space\n",
    "\n",
    "args = {}\n",
    "\n",
    "# the problem class\n",
    "args[\"problem_class\"] = benchmarks.Rosenbrock\n",
    "\n",
    "# other problems to try,\n",
    "# see  https://pythonhosted.org/inspyred/reference.html#module-inspyred.benchmarks\n",
    "\n",
    "# unimodal\n",
    "# benchmarks.Sphere\n",
    "# benchmarks.Rosenbrock\n",
    "\n",
    "# multimodal\n",
    "# benchmarks.Griewank\n",
    "# benchmarks.Ackley\n",
    "# benchmarks.Rastrigin\n",
    "# benchmarks.Schwefel\n",
    "\n",
    "# common parameters\n",
    "args[\"max_generations\"] = 100  # Number of generations\n",
    "args[\"pop_size\"] = 50  # population size\n",
    "\n",
    "# parameters for the GA\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "\n",
    "# parameters for the ES\n",
    "args[\"num_offspring\"] = 100  # lambda\n",
    "args[\"sigma\"] = 1.0  # default standard deviation\n",
    "args[\"strategy_mode\"] = es.INDIVIDUAL  # es.GLOBAL, es.INDIVIDUAL, None\n",
    "args[\"mixing_number\"] = 1  # rho\n",
    "\n",
    "# parameters for the PSO\n",
    "args[\"topology\"] = pso.RING  # pso.RING, pso.STAR\n",
    "args[\"neighborhood_size\"] = 5  # used only for the ring topology\n",
    "args[\"inertia\"] = 0.5\n",
    "args[\"cognitive_rate\"] = 2.1\n",
    "args[\"social_rate\"] = 2.1\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "rng = NumpyRandomWrapper(seed=41)\n",
    "\n",
    "# Run GA\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "best_individual, best_fitness, final_pop = ga.run_ga(\n",
    "    rng, num_vars=num_vars, display=display, use_log_scale=True, **args\n",
    ")\n",
    "print(\"Best GA fitness:\", best_fitness)\n",
    "\n",
    "# Run ES\n",
    "args[\"fig_title\"] = \"ES\"\n",
    "best_individual, best_fitness, final_pop = es.run_es(\n",
    "    rng, num_vars=num_vars, display=display, use_log_scale=True, **args\n",
    ")\n",
    "print(\"Best ES fitness:\", best_fitness)\n",
    "\n",
    "# Run PSO\n",
    "args[\"fig_title\"] = \"PSO\"\n",
    "best_individual, best_fitness, final_pop = pso.run_pso(\n",
    "    rng, num_vars=num_vars, display=display, use_log_scale=True, **args\n",
    ")\n",
    "print(\"Best PSO fitness:\", best_fitness)\n",
    "\n",
    "ioff()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Exercise 3 (Optional)\n",
    "\n",
    "Now that you have some intuition on how an existing implementation of PSO works (as well as the underlying biological inspiration), you might find useful implementing a PSO algorithm on your own (in Python or any other language of your choice). As we have seen in the lecture, this can be coded in just a few lines. If you want, try to implement a **simple** version of PSO (with the parametrization found in the previous exercise), to minimize for instance the Sphere function. You could also try to include some constraints and a constraint handling technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Instructions and questions\n",
    "\n",
    "Concisely note down your observations from the previous exercises (follow the bullet points) and think about the following questions. \n",
    "\n",
    "- When do you think it is useful to have a lower (higher) cognitive learning rate? What about the social learning rate?\n",
    "- From a biological point of view, which neighborhood topology do you consider as the most plausible?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
