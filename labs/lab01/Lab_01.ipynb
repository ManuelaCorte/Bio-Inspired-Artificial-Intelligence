{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Goal.\n",
    "The goal of this lab is to perform some preliminary experiments aimed at understanding some advantages and pitfalls of Evolutionary Algorithms (EAs). In particular, you will observe the effects of mutations and problem dimensionality, and reflect to what extent these observations also apply to biological evolution.\n",
    "\n",
    "Note that, unless otherwise specified, in this module's exercises we will use real-valued genotypes. \n",
    "I.e., an individual is a vector of real-valued parameters $\\mathbf{x} = \\{x_1, x_2, \\dots, x_N\\}$ (however, keep in mind that other types of individual representations are possible, such as trees or bit strings, which will not be explored in this lab). The fitness of an individual is given by the fitness function $f(\\mathbf{x})$. The aim of the algorithms will be to *minimize* the fitness function $f(\\mathbf{x})$, i.e. to find the vector $\\mathbf{x}_{min}$ that has the lowest value $f(\\mathbf{x})$. In other words, lower values $f(\\mathbf{x})$ correspond to a better fitness!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Exercise 1\n",
    "In this first exercise, we will not yet run a complete EA. Instead, we consider a single parent individual **$x_{0}$**, from which a number of offspring individuals are created using a Gaussian mutation operator (perturbe a point locally according to a Gaussain) (which adds a random number from a Gaussian distribution with mean zero and standard deviation $\\sigma$ to each parameter $x_i$ of the parent). The fitness function, shown in the figure below for $N=2$ variables, is defined as:\n",
    " \n",
    "$f(\\mathbf{x}) = \\sum_{i=1}^{N}{x^2_i}$\n",
    "\n",
    "![sphere.png](img/sphere.png)\n",
    "\n",
    "This function is usually defined to as *sphere* function $^{[1]}$ and is one of the most used benchmark functions in continuous (real-valued) optimization. This fitness function is unimodal, i.e. it has a single global minimum at the origin. Furthermore, this function is *scalable*, i.e. it can be defined for any arbitrary number of variables ($N=1, 2, 3, ...$, i.e. $N \\in \\mathbb{N}$).\n",
    "We will analyze the effects of mutations on the fitness depending on the value of the parent $\\mathbf{x}_0$, the mutation magnitude $^{[2]}$ (the standard deviation $\\sigma$), and the number of dimensions $N$ of the search space.\n",
    "\n",
    "To start the experiments, run the next cell $^{[3]}$. It willl generate offspring from a single parent $\\mathbf{x}_0$ using a Gaussian mutation operator (which adds a random number from a Gaussian distribution with mean zero and standard deviation $\\sigma$ to the parent). Generate offspring from different parents (e.g. $\\mathbf{x}_0$=0.1, 1, 10) using different mutation magnitudes (standard deviations $\\sigma$). First consider the one-dimensional case, then two dimensions, and finally many dimensions (e.g. $N =100$). For one or two dimensions, the fitness landscape with the parent and the offspring is shown. For more dimensions, a __[boxplot](http://matplotlib.org/api/pyplot_api.html\\#matplotlib.pyplot.boxplot)__ if you are unfamiliar with boxplots with the fitness of the offspring is shown where the green, dashed line is the fitness of the parent (we want our perturbations to have a smaller fitness value than the parent).\n",
    "\n",
    "Try to answer the following questions:\n",
    "\n",
    "- Do the mutations tend to improve or worsen the fitness of the parent?\n",
    "- Are low or high mutation magnitudes best for improving the fitness? How does this depend on the initial value of the parent and on the number of dimensions of the search space?\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "[1]: \n",
    "Note that its contour lines, i.e. the loci of points for which the function has a constant value, are $N$-dimensional *spheres* centered in **0**. For instance, in 2-D, the contour lines are curves described by $x^2_1+x^2_2=k$, which correspond to a circle (the equivalent of a sphere in 2 dimension) with radius $\\sqrt{k}$ and center in $\\{0,0\\}$. In 3-D, the contour lines are curves described by $x^2_1+x^2_2+x^2_3=k$, which correspond to a sphere with radius $\\sqrt{k}$ and center in $\\{0,0,0\\}$. For $N>3$, each contour line corresponds to a *hyper-sphere*, i.e. a generalization of a sphere.\n",
    "\n",
    "[2]: \n",
    "In the following, *mutation magnitude* indicates a generic measure of the mutation effect on the genotype. E.g. in continuous optimization with Gaussian mutation $x'=x+\\mathcal{N}(0, \\sigma$) the *mutation magnitude* is simply $\\sigma$. This is different from the *mutation probability*, that is the chance that a given loci would be mutated. The combination of these two aspects, magnitude and probability, may be considered the overall *mutation rate*.] \n",
    "\n",
    "[3]: \n",
    "For all the exercises in this lab you may set the seed for the pseudo-random number generator. This will allow you to reproduce your results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change std_dev\n",
    "from utils.ga import generate_offspring, run_ga\n",
    "from utils.simulation import run_ga_simulation, plot_boxplot\n",
    "from random import Random\n",
    "from scipy.stats import ttest_1samp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from inspyred.benchmarks import Sphere\n",
    "\n",
    "\n",
    "x0 = [10.0, 10.0]\n",
    "std_dev = 1\n",
    "num_offspring = 1000\n",
    "\n",
    "\n",
    "std_devs = [0.1, 1, 10, 100]\n",
    "for std_dev in std_devs:\n",
    "    args = {}\n",
    "    args[\"fig_title\"] = f\"std_dev = {std_dev}\"\n",
    "    seed = int(100 * std_dev)\n",
    "    rng = Random(seed)\n",
    "    parent_fitness, offspring_fitnesses = generate_offspring(\n",
    "        rng, x0, std_dev, num_offspring, True, args\n",
    "    )\n",
    "\n",
    "    fig = plt.figure(\"Offspring fitness\")\n",
    "    ax = fig.gca()\n",
    "    ax.boxplot(offspring_fitnesses)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.plot([0, 2], [parent_fitness, parent_fitness], \"g--\", label=\"Parent fitness\")\n",
    "    ax.set_ylabel(\"Fitness\")\n",
    "    ax.set_ylim(ymin=0)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    ttest = ttest_1samp(offspring_fitnesses, parent_fitness)\n",
    "    print(\n",
    "        \"p-value that offspring fitnesses are from the same distribution as parent fitness: \",\n",
    "        ttest.pvalue,  # type:ignore\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change num_dimensions\n",
    "\n",
    "x0 = [10.0, 10.0]\n",
    "std_dev = 1\n",
    "num_offspring = 1000\n",
    "\n",
    "initial_points = [[20.0], [20.0, 20.0], [20.0] * 10, [20.0] * 100]\n",
    "for x0 in initial_points:\n",
    "    args = {}\n",
    "    args[\"fig_title\"] = f\"Number dimensions = {len(x0)}\"\n",
    "    seed = int(100 * std_dev)\n",
    "    rng = Random(seed)\n",
    "    parent_fitness, offspring_fitnesses = generate_offspring(\n",
    "        rng, x0, std_dev, num_offspring, True, args\n",
    "    )\n",
    "\n",
    "    fig = plt.figure(\"Offspring fitness\")\n",
    "    ax = fig.gca()\n",
    "    ax.boxplot(offspring_fitnesses)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.plot([0, 2], [parent_fitness, parent_fitness], \"g--\", label=\"Parent fitness\")\n",
    "    ax.set_ylabel(\"Fitness\")\n",
    "    ax.set_ylim(ymin=0)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    ttest = ttest_1samp(offspring_fitnesses, parent_fitness)\n",
    "    print(\n",
    "        \"p-value that offspring fitnesses are from the same distribution as parent fitness: \",\n",
    "        ttest.pvalue,  # type:ignore\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "In this exercise we will try to confirm the observations that we did qualitatively in the previous exercise, by plotting boxplots side-by-side to evaluate the statistical significance of observed differences.\n",
    "\n",
    "Run the next cell, and compare different values for:\n",
    "\n",
    "- the number of dimensions of the search space;\n",
    "- the value of the parent (how close the starting point is to the optimum);\n",
    "- the mutation magnitude $\\sigma$ (smaller $\\sigma$ gives on average smaller mutations from the parent);\n",
    "\n",
    "and try to confirm the answers that you gave in the previous exercise. See the comments in the script for more details.\n",
    "\n",
    "**NOTE**: If you vary one of these three parameters, *make sure that you set the other two at a constant value* (otherwise it may be difficult to interpret your results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change starting point\n",
    "\n",
    "# Number of dimensions\n",
    "num_vars_1 = 2\n",
    "num_vars_2 = 2\n",
    "num_vars_3 = 2\n",
    "# How close the parent is to the minimum\n",
    "value_1 = 1\n",
    "value_2 = 10\n",
    "value_3 = 20\n",
    "# Value of the parent\n",
    "x0_1 = value_1 * np.ones(num_vars_1)\n",
    "x0_2 = value_2 * np.ones(num_vars_2)\n",
    "x0_3 = value_3 * np.ones(num_vars_3)\n",
    "# standard deviation of the mutation\n",
    "std_dev_1 = 5\n",
    "std_dev_2 = 5\n",
    "std_dev_3 = 5\n",
    "# Number of offspring to be generated\n",
    "num_offspring = 200\n",
    "\n",
    "args = {}\n",
    "seed = 100\n",
    "rng = Random(seed)\n",
    "# Generate offspring for the three conditions\n",
    "parent_fitness_1, offspring_fitness_1 = generate_offspring(\n",
    "    rng, x0_1, std_dev_1, num_offspring, False, args\n",
    ")\n",
    "parent_fitness_2, offspring_fitness_2 = generate_offspring(\n",
    "    rng, x0_2, std_dev_2, num_offspring, False, args\n",
    ")\n",
    "parent_fitness_3, offspring_fitness_3 = generate_offspring(\n",
    "    rng, x0_3, std_dev_3, num_offspring, False, args\n",
    ")\n",
    "\n",
    "fig = plt.figure(\"Offspring fitness\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot([offspring_fitness_1, offspring_fitness_2, offspring_fitness_3], notch=False)\n",
    "ax.plot([0.5, 1.5], [parent_fitness_1, parent_fitness_1], \"g--\", label=\"Parent fitness\")\n",
    "ax.plot([1.5, 2.5], [parent_fitness_2, parent_fitness_2], \"g--\")\n",
    "ax.plot([2.5, 3.5], [parent_fitness_3, parent_fitness_3], \"g--\")\n",
    "ax.set_xticklabels([f\"{x0_1}\", f\"{x0_2}\", f\"{x0_3}\"])\n",
    "ax.set_xlabel(\"Starting Point\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"mean for condition 1\", np.mean(offspring_fitness_1))\n",
    "print(\n",
    "    \"t test for condition 1\",\n",
    "    ttest_1samp(offspring_fitness_1, popmean=parent_fitness_1).pvalue,  # type:ignore\n",
    ")\n",
    "print(\"mean for condition 2\", np.mean(offspring_fitness_2))\n",
    "print(\n",
    "    \"t test for condition 2\",\n",
    "    ttest_1samp(offspring_fitness_2, popmean=parent_fitness_2).pvalue,  # type:ignore\n",
    ")\n",
    "print(\"mean for condition 3\", np.mean(offspring_fitness_3))\n",
    "print(\n",
    "    \"t test for condition 3\",\n",
    "    ttest_1samp(offspring_fitness_3, popmean=parent_fitness_3).pvalue,  # type:ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change number of dimensions\n",
    "\n",
    "# Number of dimensions\n",
    "num_vars_1 = 2\n",
    "num_vars_2 = 10\n",
    "num_vars_3 = 100\n",
    "# How close the parent is to the minimum\n",
    "value_1 = 10\n",
    "value_2 = 10\n",
    "value_3 = 10\n",
    "# Value of the parent\n",
    "x0_1 = value_1 * np.ones(num_vars_1)\n",
    "x0_2 = value_2 * np.ones(num_vars_2)\n",
    "x0_3 = value_3 * np.ones(num_vars_3)\n",
    "# standard deviation of the mutation\n",
    "std_dev_1 = 5\n",
    "std_dev_2 = 5\n",
    "std_dev_3 = 5\n",
    "# Number of offspring to be generated\n",
    "num_offspring = 200\n",
    "\n",
    "args = {}\n",
    "seed = 100\n",
    "rng = Random(seed)\n",
    "# Generate offspring for the three conditions\n",
    "parent_fitness_1, offspring_fitness_1 = generate_offspring(\n",
    "    rng, x0_1, std_dev_1, num_offspring, False, args\n",
    ")\n",
    "parent_fitness_2, offspring_fitness_2 = generate_offspring(\n",
    "    rng, x0_2, std_dev_2, num_offspring, False, args\n",
    ")\n",
    "parent_fitness_3, offspring_fitness_3 = generate_offspring(\n",
    "    rng, x0_3, std_dev_3, num_offspring, False, args\n",
    ")\n",
    "\n",
    "fig = plt.figure(\"Offspring fitness\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot([offspring_fitness_1, offspring_fitness_2, offspring_fitness_3], notch=False)\n",
    "ax.plot([0.5, 1.5], [parent_fitness_1, parent_fitness_1], \"g--\", label=\"Parent fitness\")\n",
    "ax.plot([1.5, 2.5], [parent_fitness_2, parent_fitness_2], \"g--\")\n",
    "ax.plot([2.5, 3.5], [parent_fitness_3, parent_fitness_3], \"g--\")\n",
    "ax.set_xticklabels([f\"{num_vars_1}\", f\"{num_vars_2}\", f\"{num_vars_3}\"])\n",
    "ax.set_xlabel(\"Dimensions\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"mean for condition 1\", np.mean(offspring_fitness_1))\n",
    "print(\n",
    "    \"t test for condition 1\",\n",
    "    ttest_1samp(offspring_fitness_1, popmean=parent_fitness_1).pvalue,  # type:ignore\n",
    ")\n",
    "print(\"mean for condition 2\", np.mean(offspring_fitness_2))\n",
    "print(\n",
    "    \"t test for condition 2\",\n",
    "    ttest_1samp(offspring_fitness_2, popmean=parent_fitness_2).pvalue,  # type:ignore\n",
    ")\n",
    "print(\"mean for condition 3\", np.mean(offspring_fitness_3))\n",
    "print(\n",
    "    \"t test for condition 3\",\n",
    "    ttest_1samp(offspring_fitness_3, popmean=parent_fitness_3).pvalue,  # type:ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change standard deviation\n",
    "\n",
    "# Number of dimensions\n",
    "num_vars_1 = 2\n",
    "num_vars_2 = 2\n",
    "num_vars_3 = 2\n",
    "# How close the parent is to the minimum\n",
    "value_1 = 10\n",
    "value_2 = 10\n",
    "value_3 = 10\n",
    "# Value of the parent\n",
    "x0_1 = value_1 * np.ones(num_vars_1)\n",
    "x0_2 = value_2 * np.ones(num_vars_2)\n",
    "x0_3 = value_3 * np.ones(num_vars_3)\n",
    "# standard deviation of the mutation\n",
    "std_dev_1 = 1\n",
    "std_dev_2 = 5\n",
    "std_dev_3 = 10\n",
    "# Number of offspring to be generated\n",
    "num_offspring = 200\n",
    "\n",
    "args = {}\n",
    "seed = 100\n",
    "rng = Random(seed)\n",
    "# Generate offspring for the three conditions\n",
    "parent_fitness_1, offspring_fitness_1 = generate_offspring(\n",
    "    rng, x0_1, std_dev_1, num_offspring, False, args\n",
    ")\n",
    "parent_fitness_2, offspring_fitness_2 = generate_offspring(\n",
    "    rng, x0_2, std_dev_2, num_offspring, False, args\n",
    ")\n",
    "parent_fitness_3, offspring_fitness_3 = generate_offspring(\n",
    "    rng, x0_3, std_dev_3, num_offspring, False, args\n",
    ")\n",
    "\n",
    "fig = plt.figure(\"Offspring fitness\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot([offspring_fitness_1, offspring_fitness_2, offspring_fitness_3], notch=False)\n",
    "ax.plot([0.5, 1.5], [parent_fitness_1, parent_fitness_1], \"g--\", label=\"Parent fitness\")\n",
    "ax.plot([1.5, 2.5], [parent_fitness_2, parent_fitness_2], \"g--\")\n",
    "ax.plot([2.5, 3.5], [parent_fitness_3, parent_fitness_3], \"g--\")\n",
    "ax.set_xticklabels([f\"{std_dev_1}\", f\"{std_dev_2}\", f\"{std_dev_3}\"])\n",
    "ax.set_xlabel(\"Standard deviation\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"mean for condition 1\", np.mean(offspring_fitness_1))\n",
    "print(\n",
    "    \"t test for condition 1\",\n",
    "    ttest_1samp(offspring_fitness_1, popmean=parent_fitness_1).pvalue,  # type:ignore\n",
    ")\n",
    "print(\"mean for condition 2\", np.mean(offspring_fitness_2))\n",
    "print(\n",
    "    \"t test for condition 2\",\n",
    "    ttest_1samp(offspring_fitness_2, popmean=parent_fitness_2).pvalue,  # type:ignore\n",
    ")\n",
    "print(\"mean for condition 3\", np.mean(offspring_fitness_3))\n",
    "print(\n",
    "    \"t test for condition 3\",\n",
    "    ttest_1samp(offspring_fitness_3, popmean=parent_fitness_3).pvalue,  # type:ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "We will now use an EA to find the minimum of the unimodal fitness function defined in the previous exercise and analyze the effect of the mutation magnitude and the dimensionality of the search space on the results.\n",
    "\n",
    "Run the next cell to run a basic, mutation-only EA on the 1-D sphere function first.\n",
    "\n",
    "- How close is the best individual from the global optimum? \n",
    "\n",
    "Increase the dimensionality of the search space to two and more.\n",
    "\n",
    "- How close are the best individuals now from the global optimum?\n",
    "- Can you get as close as in the one-dimensional case by modifying the mutation magnitude and/or the number of generations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 1  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "args[\"num_vars\"] = 1\n",
    "args[\"std_dev\"] = 0.5\n",
    "args[\"max_generations\"] = 100\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"Sphere Function\"\n",
    "\n",
    "# Run the GA\n",
    "results = run_ga_simulation(\n",
    "    func=Sphere, num_simulations=10, args=args, print_plots=True\n",
    ")  # type:ignore\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean Best Individual:\", results.mean_best_individual)\n",
    "print(\"Mean Best Fitness:\", results.mean_best_fitness)\n",
    "# The distance from the optimum in the N-dimensional space\n",
    "print(\n",
    "    \"Distance from Global Optimum\",\n",
    "    np.sqrt(np.sum(np.array(results.mean_best_individual) ** 2)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 1  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "args[\"num_vars\"] = 10\n",
    "args[\"std_dev\"] = 0.1\n",
    "args[\"max_generations\"] = 250\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"Sphere Function\"\n",
    "\n",
    "# Run the GA\n",
    "results = run_ga_simulation(\n",
    "    func=Sphere, num_simulations=10, args=args, print_plots=True\n",
    ")  # type:ignore\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean Best Individual:\", results.mean_best_individual)\n",
    "print(\"Mean Best Fitness:\", results.mean_best_fitness)\n",
    "# The distance from the optimum in the N-dimensional space\n",
    "print(\n",
    "    \"Distance from Global Optimum\",\n",
    "    np.sqrt(np.sum(np.array(results.mean_best_individual) ** 2)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from inspyred.benchmarks import Sphere\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 1.0  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "args[\"num_vars\"] = 2\n",
    "args[\"std_dev\"] = 1\n",
    "args[\"max_generations\"] = 100\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "\n",
    "mutations = [0.05, 0.1, 1, 5, 10]\n",
    "best_fitnesses: list[list[float]] = []\n",
    "for mutation in mutations:\n",
    "    args[\"fig_title\"] = f\"Sphere Function (std {mutation})\"\n",
    "    print(f\"Mutation standard deviation: {mutation}\")\n",
    "    args[\"std_dev\"] = mutation\n",
    "    results = run_ga_simulation(\n",
    "        func=Sphere, num_simulations=30, args=args, print_plots=False\n",
    "    )  # type:ignore\n",
    "    best_fitnesses.append(results.all_best_fitness)\n",
    "    # Display the results\n",
    "    print(\"Mean Best Individual:\", results.mean_best_individual)\n",
    "    print(\"Mean Best Fitness:\", results.mean_best_fitness)\n",
    "    # The distance from the optimum in the N-dimensional space\n",
    "    print(\n",
    "        \"Distance from Global Optimum\",\n",
    "        np.sqrt(np.sum(np.array(results.mean_best_individual) ** 2)),\n",
    "    )\n",
    "    print(\"-------------------------------------------\")\n",
    "    plt.show()\n",
    "\n",
    "plot_boxplot(best_fitnesses, mutations, \"Standard Deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from inspyred.benchmarks import Sphere\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 5.0  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "args[\"num_vars\"] = 2\n",
    "args[\"std_dev\"] = 1\n",
    "args[\"max_generations\"] = 100\n",
    "\n",
    "\n",
    "generations = [10, 50, 100, 200]\n",
    "best_fitnesses: list[list[float]] = []\n",
    "for gen in generations:\n",
    "    print(f\"Number of generations: {gen}\")\n",
    "    args[\"fig_title\"] = f\"Sphere Function (gen {gen})\"\n",
    "    args[\"max_generations\"] = gen\n",
    "    results = run_ga_simulation(\n",
    "        func=Sphere, num_simulations=30, args=args, print_plots=False\n",
    "    )  # type:ignore\n",
    "    best_fitnesses.append(results.all_best_fitness)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Mean Best Individual:\", results.mean_best_individual)\n",
    "    print(\"Mean Best Fitness:\", results.mean_best_fitness)\n",
    "    # The distance from the optimum in the N-dimensional space\n",
    "    print(\n",
    "        \"Distance from Global Optimum\",\n",
    "        np.sqrt(np.sum(np.array(results.mean_best_individual) ** 2)),\n",
    "    )\n",
    "    print(\"-------------------------------------------\")\n",
    "    plt.show()\n",
    "\n",
    "plot_boxplot(best_fitnesses, generations, \"Number of Generations\")  # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from inspyred.benchmarks import Sphere\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 5.0  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "args[\"num_vars\"] = 2\n",
    "args[\"std_dev\"] = 1\n",
    "args[\"max_generations\"] = 100\n",
    "\n",
    "dimensions = [1, 2, 10, 100]\n",
    "best_fitnesses: list[list[float]] = []\n",
    "for num_vars in dimensions:\n",
    "    print(f\"Number of dimensions: {num_vars}\")\n",
    "    args[\"fig_title\"] = f\"Sphere Function (dim {num_vars})\"\n",
    "    args[\"num_vars\"] = num_vars\n",
    "    results = run_ga_simulation(\n",
    "        func=Sphere, num_simulations=30, args=args, print_plots=False\n",
    "    )  # type:ignore\n",
    "    best_fitnesses.append(results.all_best_fitness)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Mean Best Individual:\", results.mean_best_individual)\n",
    "    print(\"Mean Best Fitness:\", results.mean_best_fitness)\n",
    "    # The distance from the optimum in the N-dimensional space\n",
    "    print(\n",
    "        \"Distance from Global Optimum\",\n",
    "        np.sqrt(np.sum(np.array(results.mean_best_individual) ** 2)),\n",
    "    )\n",
    "    print(\"-------------------------------------------\")\n",
    "    plt.show()\n",
    "\n",
    "plot_boxplot(best_fitnesses, dimensions, \"Number of Dimensions\")  # type:ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "In this exercise we will try to confirm the observations that we did qualitatively in the previous exercise, by plotting boxplots side-by-side to evaluate the statistical significance of observed differences.\n",
    "\n",
    "Run the next cell to do three batches of $30$ runs of the EA with different mutation magnitudes (it may take a minute). The boxplot compares the best fitness values obtained (at the end of each run) in the three conditions.\n",
    "\n",
    "- Did you see any difference in the best fitness obtained? Try to explain the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = 2  # Number of dimensions of the search space\n",
    "std_devs = [0.001, 0.01, 0.1, 1.0, 5.0]  # Standard deviation of the Gaussian mutations\n",
    "max_generations = 50  # Number of generations of the GA\n",
    "num_runs = 30  # Number of runs to be done for each stdev\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 1.0  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "display = False  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = None\n",
    "rng = Random(seed)\n",
    "# run the GA *num_runs* times for each std_dev and record the best fits\n",
    "best_fitnesses = [\n",
    "    [\n",
    "        run_ga(\n",
    "            rng,\n",
    "            num_vars=num_vars,\n",
    "            max_generations=max_generations,\n",
    "            display=display,\n",
    "            gaussian_stdev=std_dev,\n",
    "            **args,\n",
    "        )[1]\n",
    "        for _ in range(num_runs)\n",
    "    ]\n",
    "    for std_dev in std_devs\n",
    "]\n",
    "\n",
    "fig = plt.figure(\"GA (best fitness)\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot(best_fitnesses)\n",
    "ax.set_xticklabels([str(sd) for sd in std_devs])\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Std. dev.\")\n",
    "ax.set_ylabel(\"Best fitness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = 10  # Number of dimensions of the search space\n",
    "std_devs = [0.001, 0.01, 0.1, 1.0, 5.0]  # Standard deviation of the Gaussian mutations\n",
    "max_generations = 50  # Number of generations of the GA\n",
    "num_runs = 30  # Number of runs to be done for each stdev\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 1.0  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "display = False  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = None\n",
    "rng = Random(seed)\n",
    "# run the GA *num_runs* times for each std_dev and record the best fits\n",
    "best_fitnesses = [\n",
    "    [\n",
    "        run_ga(\n",
    "            rng,\n",
    "            num_vars=num_vars,\n",
    "            max_generations=max_generations,\n",
    "            display=display,\n",
    "            gaussian_stdev=std_dev,\n",
    "            **args,\n",
    "        )[1]\n",
    "        for _ in range(num_runs)\n",
    "    ]\n",
    "    for std_dev in std_devs\n",
    "]\n",
    "\n",
    "fig = plt.figure(\"GA (best fitness)\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot(best_fitnesses)\n",
    "ax.set_xticklabels([str(sd) for sd in std_devs])\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Std. dev.\")\n",
    "ax.set_ylabel(\"Best fitness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Sphere function with a single parent individual **$x_{0}$**, from which a number of offspring individuals are created using a Gaussian mutation operator.\n",
    "\n",
    "As a first step we analyze the effects of the mutation magnitude $\\sigma$ on the fitness depending on the value of the parent $\\mathbf{x}_0$ and the number of dimensions $N$ of the search space.\n",
    "\n",
    " We can see that the offsprings are distributed around the parent and, based on the mutation rate, their spread is more or less wide. The only exception is for  very large mutations (here 10) where the offsprings aren't equally distributed around the parent because the mutation is large enough to reach the global minimum.\n",
    " \n",
    " ![sd0.1](img/ex1_sd01_pop.png)   ![sd0.1](img/ex1_sd01_fit.png) \n",
    "\n",
    " ![sd0.1](img/ex1_sd1_pop.png)    ![sd1](img/ex1_sd1_fit.png) \n",
    " \n",
    " ![sd0.1](img/ex1_sd10_pop.png)   ![sd1](img/ex1_sd10_fit.png) \n",
    "\n",
    "\n",
    "Now the observe the effect of the mutation magnitude based on the number of dimensions.\n",
    "\n",
    "![1D](img/ex1_1d.png) ![2D](img/ex1_2d.png) ![10D](img/ex1_10d.png)\n",
    "\n",
    "The only interesting thing to note is that the fitness of the parent (and as a consequence the fitness of the offspring) is higher in higher dimensions. This is because the fitness function is the sum of the squares of the parameters, so the more parameters we have, the higher the fitness will be.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "We will try to confirm the observations that we did qualitatively in the previous exercise, by plotting boxplots side-by-side to evaluate the statistical significance of observed differences.\n",
    "\n",
    "### Initial Point\n",
    "Observing the boxplots, we can see that the closer the initial point is to the global minimum, the more effective the mutation is. This is because the offspring are more likely to be closer to the global minimum.\n",
    "\n",
    "![Initial Point](img/ex2_init_point.png)\n",
    "\n",
    "### Number of Dimensions\n",
    "We can see that the larger the number of dimensions, the fitness of the parent is better than that of its offspring. This is because the mutation is applied to each dimension, so the more dimensions we have, the more likely the offspring will be far from the global minimum.\n",
    "\n",
    "![Number of Dimensions](img/ex2_dim.png)\n",
    "\n",
    "### Mutation Magnitude\n",
    "We can see that the larger the mutation magnitude, the more spread out the offsprings are. In this case, since there is only a global minimum, the larger the mutation the better because the offspring are more likely to reach the minimum \n",
    "\n",
    "![Mutation Magnitude](img/ex2_sd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "EA to find the minimum of the unimodal sphere function with a different number of dimensions.\n",
    "\n",
    "### 1D\n",
    "We ran the EA with a mutation of 0.5 and 100 generations. The EA was then repeated 30 times to get the average best individual and fitness.\n",
    "\n",
    "Mean Best Individual: [0.00091159]\n",
    "\n",
    "Mean Best Fitness: 2.670713845142703e-06\n",
    "\n",
    "Distance from Global Optimum 0.0009115875196680715\n",
    "\n",
    "![1D](img/ex3_sphere_1d_fit.png) | ![1D](img/ex3_sphere_1d_pop.png)\n",
    "\n",
    "### 10D\n",
    "We ran the EA with a mutation of 0.1 and 250 generations. The EA was then repeated 30 times to get the average best individual and fitness. Increasing the number of generations and decreasing the mutation helped to get close to the global minimum but past this point not much improvement was seen.\n",
    "\n",
    "Mean Best Individual: [ 0.05436666 -0.04087693 -0.18585926  0.23645044  0.10731215  0.15161582 -0.12307874 -0.02372709 -0.01918248 -0.06533183]\n",
    "\n",
    "Mean Best Fitness: 1.9201467949492432\n",
    "\n",
    "Distance from Global Optimum 0.3872078945527439\n",
    "\n",
    "![10D](img/ex3_sphere_10d_fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Comparison over multiple runs of the EA with different mutation magnitudes. We can see that the larger mutation magnitudes aren't as effective probably because the mutation is so large than the individuals \"jump\" over the global minimum. While a too small mutation rate is ineffective because the offspring are too close and don't explore the search space.\n",
    "\n",
    "![Boxplot](img/ex4.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
