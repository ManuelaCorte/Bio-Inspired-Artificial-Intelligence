{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Goal\n",
    "The goal of this lab is to familiarize yourself with some of the constraints handling techniques used in Evolutionary Computation.\n",
    "\n",
    "Note once again that, unless otherwise specified, in this module's exercises we will use real-valued genotypes and that the aim of the algorithms will be to *minimize* the fitness function $f(\\mathbf{x})$, i.e. lower values correspond to a better fitness!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "In this exercise we will continue the investigation of the multiple-disk clutch brake design problem we have seen in the previous lab. In this case, we will consider the full problem including a number of constraints $g_i(x)$, as defined in Figure below. The constraints have been implemented for you in the provided `disk_clutch_brake.py`. Please note that the only difference with respect to the code we have seen in the previous lab is the activation of the constraints, obtained by setting the variable `constrained` to `True` in Exercise 1 (equivalent to Exercise 3 from the previous lab).\n",
    "\n",
    "<img src=\"img/clutch-brake-definition.png\" alt=\"Alternative text\" />\n",
    "\n",
    "When constraints are enforced the notion of constrained-Pareto-domination comes into play. A solution $i$ now is considered to dominate a solution $j$ if any of the following conditions are true:\n",
    "\n",
    "- Solution $i$ is feasible and solution $j$ is not\n",
    "- Solutions $i$ and $j$ are both infeasible, but solution $i$ has a smaller overall constraint violation.\n",
    "- Solutions $i$ and $j$ are feasible and solution $i$ dominates solution $j$\n",
    "\n",
    "As in the previous lab, the final population and fitness values are saved on a file `exercise_1.csv` \\{$r_i$, $r_o$, $t$, $F$, $Z$, $mass$, $time$\\}, one line for each solution in the Pareto front. Also in this case, you may want to try plotting these data in different ways to gain further insights.\n",
    "\n",
    "- How do your results change from the unconstrained version (from the previous lab)?\n",
    "- Do your previous parameters continue to solve the problem?\n",
    "- Try to increase the population size and/or the number of generations to see if you can find better solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspyred.ec import variators\n",
    "\n",
    "from utils.inspyred_utils import NumpyRandomWrapper\n",
    "from utils.multi_objective import run_nsga2\n",
    "from utils.disk_clutch_brake import DiskClutchBrake, disk_clutch_brake_mutation\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Optional\n",
    "import utils.constrained_benchmarks as cb\n",
    "from utils.es import run_es\n",
    "from inspyred import ec\n",
    "from utils.ga import run_ga\n",
    "\n",
    "\n",
    "def plot_final_pop(\n",
    "    function: Any,\n",
    "    final_pop: list[ec.Individual],\n",
    "    minimize: bool = True,\n",
    "    bounds: Optional[tuple[tuple[float, float], tuple[float, float]]] = None,\n",
    "):\n",
    "    x_feasible = []\n",
    "    y_feasible = []\n",
    "    x_infeasible = []\n",
    "    y_infeasible = []\n",
    "    x_best = 0.0\n",
    "    y_best = 0.0\n",
    "    final_pop.sort()\n",
    "    for i, p in enumerate(final_pop):\n",
    "        if i == len(final_pop) - 1:\n",
    "            x_best = p.candidate[0]  # type: ignore\n",
    "            y_best = p.candidate[1]  # type: ignore\n",
    "\n",
    "        g1 = (\n",
    "            function.penalty(p.candidate[0], p.candidate[1])  # type: ignore\n",
    "            if minimize\n",
    "            else -1 * function.penalty(p.candidate[0], p.candidate[1])  # type: ignore\n",
    "        )  # type: ignore\n",
    "        if g1 <= 0:\n",
    "            x_feasible.append(p.candidate[0])  # type: ignore\n",
    "            y_feasible.append(p.candidate[1])  # type: ignore\n",
    "        else:\n",
    "            x_infeasible.append(p.candidate[0])  # type: ignore\n",
    "            y_infeasible.append(p.candidate[1])  # type: ignore\n",
    "    # angles = np.linspace(0, 2 * np.pi, 100)\n",
    "\n",
    "    if bounds is not None:\n",
    "        lower_bound_1 = bounds[0][0]\n",
    "        upper_bound_1 = bounds[0][1]\n",
    "        lower_bound_2 = bounds[1][0]\n",
    "        upper_bound_2 = bounds[1][1]\n",
    "    else:\n",
    "        lower_bound_1 = function.bounder.lower_bound[0]  # type: ignore\n",
    "        upper_bound_1 = function.bounder.upper_bound[0]  # type: ignore\n",
    "        lower_bound_2 = function.bounder.lower_bound[1]  # type: ignore\n",
    "        upper_bound_2 = function.bounder.upper_bound[1]  # type: ignore\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    f.suptitle(function)\n",
    "    ax.set_xlim(lower_bound_1, upper_bound_1)\n",
    "    ax.set_ylim(lower_bound_2, upper_bound_2)\n",
    "    ax.scatter(x_feasible, y_feasible, color=\"b\", label=\"Feasible\")\n",
    "    ax.scatter(x_infeasible, y_infeasible, color=\"g\", label=\"Infeasible\")\n",
    "    ax.scatter(x_best, y_best, color=\"r\", label=\"Best\")\n",
    "    ax.legend()\n",
    "    ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = True\n",
    "\n",
    "# parameters for NSGA-2\n",
    "args = {}\n",
    "args[\"pop_size\"] = 50\n",
    "args[\"max_generations\"] = 250\n",
    "constrained = True\n",
    "\n",
    "problem = DiskClutchBrake(constrained)\n",
    "if constrained:\n",
    "    args[\"constraint_function\"] = problem.constraint_function\n",
    "args[\"objective_1\"] = \"Brake Mass (kg)\"\n",
    "args[\"objective_2\"] = \"Stopping Time (s)\"\n",
    "\n",
    "args[\"variator\"] = [variators.blend_crossover, disk_clutch_brake_mutation]\n",
    "\n",
    "args[\"fig_title\"] = \"NSGA-2\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "final_pop, final_pop_fitnesses = run_nsga2(\n",
    "    rng, problem, display=display, num_vars=5, **args\n",
    ")\n",
    "\n",
    "print(\"Final Population\\n\", final_pop)\n",
    "print()\n",
    "print(\"Final Population Fitnesses\\n\", final_pop_fitnesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "In this exercise we will test the Genetic Algorithm we used in Lab 2 for solving a set of constrained optimization benchmark functions. In this case we will consider five benchmark problems from the Wikipedia page on Test functions for constrained optimization (see [link](https://en.wikipedia.org/wiki/Test_functions_for_optimization\\#Test_functions_for_constrained_optimization)), plus an additional sphere function with a constraint. We will limit the experiments only on two dimensions, to visualize the fitness landscape.\n",
    "\n",
    "Try at least one or two of the following benchmark functions:\n",
    "1. RosenbrockCubicLine\n",
    "2. RosenbrockDisk\n",
    "3. MishraBirdConstrained\n",
    "4. Townsend\n",
    "5. Simionescu\n",
    "\n",
    "You can change the problem by changing the parameter `args[problem_class]` in the cello below. By default, the constraints are ignored by the GA. In order to set the GA to handle the constraints, set the variable `usePenalty=True` in `constrained_benchmarks.py`.\n",
    "\n",
    "- Do you see any difference in the GA's behavior (and results) when the penalty is enabled or disabled?\n",
    "- Try to modify the penalty functions used in the code of each benchmark function (check the code corresponding to `if usePenalty`, and/or change the main parameters of the GA `max_generations`, `pop_size`, `gaussian_stdev`, `mutation_rate`, `tournament_size`, `num_elites`) in *Exercise 2*. Are you able to find the optimum on all the benchmark functions you tested?\n",
    "\n",
    "Now, analyze the benchmark `SphereCircle` (look at the code in `constrained_benchmarks.py`). In this case we are *maximizing* the 2-d sphere function we have already seen in the previous labs ($f(x) = x_1^2 + x_2^2$), subject to the constraint:\n",
    "$\n",
    " g_1(x) = x_1^2 + x_2^2 \\leq 1 \\longrightarrow g_1(x) = x_1^2 + x_2^2 - 1 \\leq 0\n",
    "$\n",
    "Here, candidates solutions represent ordered pairs and their fitness is simply their distance from the origin. However, the constraint punishes solutions that lie *outside* the unit circle. Such a scenario should produce an optimum that lies on the unit circle. By default, the code penalizes candidate solutions outside the unit circle by assigning them a fitness value equal to -1.\n",
    "\n",
    "- Is the GA able to find the optimal solution lying on the unit circle? If not, try to change some of the GA's parameters to reach the optimum.\n",
    "- By default, the sphere function is defined in a domain $[-5.12,5.12]$ along each dimension. Try to increase the search space (to do so, change  `self.bounder` and `generator` in the class `SphereCircle`. To progressively increasing boundaries (e.g. $[-10,10]$, $[-20,20]$, etc.). Is the GA still able to explore the feasible region and find the optimum?\n",
    "-  If not, try to think of a way to guide the GA towards the feasible region. How could you change the penalty function to do so? (Hint: look at the `evaluator` method of the class `SphereCircle` and consider that we are maximizing the fitness function, while we want to minimize the violation given by $g_1(x)$.\n",
    "\n",
    "\n",
    "Finally, you can create your own constrained optimization problem by modifying the class template  `SphereConstrained` you will find in `constrained_benchmarks.py`.\n",
    "\n",
    "- Try to modify the sphere function problem by adding one or more linear/non-linear constraints, and analyze how the optimum changes depending on the presence of constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RosenbrockCubicLine unconstrained\n",
    "problem_class = cb.RosenbrockCubicLine\n",
    "\n",
    "args = {}\n",
    "args[\"problem_class\"] = problem_class\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = False\n",
    "args[\"fig_title\"] = f\"GA - {problem_class.__name__} Unconstrained\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_class = cb.RosenbrockCubicLine\n",
    "\n",
    "args = {}\n",
    "args[\"problem_class\"] = problem_class\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = True\n",
    "args[\"fig_title\"] = f\"GA - {problem_class.__name__} Constrained\"\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simonescu unconstrained\n",
    "\n",
    "problem_class = cb.Simionescu\n",
    "\n",
    "args = {}\n",
    "args[\"problem_class\"] = problem_class\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = False\n",
    "args[\"fig_title\"] = f\"GA - {problem_class.__name__} Unconstrained\"\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simonescu constrained\n",
    "problem_class = cb.Simionescu\n",
    "\n",
    "args = {}\n",
    "args[\"problem_class\"] = problem_class\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.8  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = True\n",
    "args[\"fig_title\"] = f\"GA - {problem_class.__name__} Constrained\"\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Townsend unconstrained\n",
    "\n",
    "problem_class = cb.Townsend\n",
    "\n",
    "args = {}\n",
    "args[\"problem_class\"] = problem_class\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.8  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = False\n",
    "args[\"fig_title\"] = f\"GA - {problem_class.__name__} Unconstrained\"\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Townsend constrained\n",
    "\n",
    "problem_class = cb.Townsend\n",
    "\n",
    "args = {}\n",
    "args[\"problem_class\"] = problem_class\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.8  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = True\n",
    "args[\"fig_title\"] = f\"GA - {problem_class.__name__} Constrained\"\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MishraBird Unconstrained\n",
    "\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.8  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"problem_class\"] = cb.MishraBirdConstrained\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = False\n",
    "args[\"fig_title\"] = f\"GA - {args['problem_class'].__name__}\"\n",
    "\n",
    "display = True\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MishraBird Constrained\n",
    "\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.8  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"problem_class\"] = cb.MishraBirdConstrained\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = True\n",
    "args[\"fig_title\"] = f\"GA - {args['problem_class'].__name__}\"\n",
    "\n",
    "display = True\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, display=display, num_vars=2, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)  # type: ignore\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual found:\", best_individual)\n",
    "print(\"Best Fitness found:\", best_fitness)\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local functions\n",
    "class SphereConstrained(cb.ConstrainedBenchmark):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimensions: int = 2,\n",
    "        use_penalty: bool = True,\n",
    "        bounder: Optional[list[list[float]]] = None,\n",
    "        penalty_factor: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        cb.Benchmark.__init__(self, dimensions)\n",
    "        self.bounder = ec.Bounder([-5.12] * self.dimensions, [5.12] * self.dimensions)\n",
    "        self.maximize = False\n",
    "        self.global_optimum = [0 for _ in range(self.dimensions)]\n",
    "        self.use_penalty = use_penalty\n",
    "        self.penalty_factor = penalty_factor\n",
    "\n",
    "    def generator(\n",
    "        self, random: NumpyRandomWrapper, args: dict[str, Any]\n",
    "    ) -> list[float]:\n",
    "        return [random.uniform(-5.12, 5.12) for _ in range(self.dimensions)]\n",
    "\n",
    "    def evaluator(\n",
    "        self, candidates: list[list[float]], args: dict[str, Any]\n",
    "    ) -> list[float]:\n",
    "        fitness: list[float] = []\n",
    "        for c in candidates:\n",
    "            f = self.f(c[0], c[1])\n",
    "            if self.use_penalty:\n",
    "                # penalty function (note that in this case we are minimizing, so we add a positive value).\n",
    "                g1 = self.g1(c[0], c[1])\n",
    "                g2 = self.g2(c[0], c[1])\n",
    "                g3 = self.g3(c[0], c[1])\n",
    "                if g1 > 0 or g2 > 0 or g3 > 0:\n",
    "                    if self.penalty_factor is None:\n",
    "                        # adaptive penalty\n",
    "                        f += (\n",
    "                            self.bounder.upper_bound[0] - self.bounder.lower_bound[0]  # type: ignore\n",
    "                        ) * abs(g1 + g2 + g3)\n",
    "                    else:\n",
    "                        # static penalty\n",
    "                        f += self.penalty_factor\n",
    "            fitness.append(f)\n",
    "        return fitness\n",
    "\n",
    "    def constraintsEvaluator(\n",
    "        self, candidates: list[list[float]], args: dict[str, Any]\n",
    "    ) -> list[list[float]]:\n",
    "        constraints: list[list[float]] = []\n",
    "        for c in candidates:\n",
    "            # Change this part to evaluate the constraints\n",
    "            g1 = self.g1(c[0], c[1])  # <=0\n",
    "            g2 = self.g2(c[0], c[1])  # <=0\n",
    "            g3 = self.g3(c[0], c[1])  # <=0\n",
    "            constraints.append([g1, g2, g3])\n",
    "        return constraints\n",
    "\n",
    "    def f(self, x: float, y: float) -> float:\n",
    "        return x**2 + y**2\n",
    "\n",
    "    # Implement here some constraints\n",
    "    def g1(self, x: float, y: float) -> float:\n",
    "        return 1 - x**2 - y**2\n",
    "\n",
    "    def g2(self, x: float, y: float) -> float:\n",
    "        return 3 * x + 4 * y - 10\n",
    "\n",
    "    def g3(self, x: float, y: float) -> float:\n",
    "        return x**3 - 2 * y - 5\n",
    "\n",
    "    def penalty(self, x: float, y: float) -> float:\n",
    "        g1 = self.g1(x, y)\n",
    "        g2 = self.g2(x, y)\n",
    "        g3 = self.g3(x, y)\n",
    "        return max(0, g1) + max(0, g2) + max(0, g3)\n",
    "\n",
    "    def printSolution(self, c: list[float]) -> None:\n",
    "        f = self.f(c[0], c[1])\n",
    "        g1 = self.g1(c[0], c[1])\n",
    "        g2 = self.g2(c[0], c[1])\n",
    "        g3 = self.g3(c[0], c[1])\n",
    "        print(\"f =\", f)\n",
    "        print(\"g1 =\", g1)\n",
    "        print(\"g2 =\", g2)\n",
    "        print(\"g3 =\", g3)\n",
    "        if g1 > 0 or g2 > 0 or g3 > 0:\n",
    "            print(\"(unfeasible)\")\n",
    "        else:\n",
    "            print(\"(feasible)\")\n",
    "\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = False\n",
    "\n",
    "args[\"problem_class\"] = SphereConstrained\n",
    "# args[\"problem_class\"] = SphereConstrained\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, num_vars=2, display=display, use_log_scale=False, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop, minimize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.8  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = True\n",
    "\n",
    "args[\"problem_class\"] = SphereConstrained\n",
    "# args[\"problem_class\"] = SphereConstrained\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, num_vars=2, display=display, use_log_scale=False, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.8  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = True\n",
    "\n",
    "args[\"problem_class\"] = cb.SphereCircle\n",
    "# args[\"problem_class\"] = SphereConstrained\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, num_vars=2, display=display, use_log_scale=False, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "print(\"Maximum: lies on the unit circle\")\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 50  # population size\n",
    "args[\"gaussian_stdev\"] = 1.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.8  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"use_penalty\"] = True\n",
    "args[\"bounder\"] = ec.Bounder([-10, 10], [-10, 10])\n",
    "args[\"problem_class\"] = cb.SphereCircle\n",
    "# args[\"problem_class\"] = SphereConstrained\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng, num_vars=2, display=display, use_log_scale=False, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "print(\"Maximum: lies on the unit circle\")\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop, bounds=((11, -11), (11, -11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Instructions and questions\n",
    "\n",
    "Concisely note down your observations from the previous exercises (follow the bullet points) and think about the following questions. \n",
    "\n",
    "- What do you think is the most efficient way to handle constraints in EAs?\n",
    "- Do you think that the presence of constraints makes the search *always* more difficult? Can you think of cases in which the constraints could actually make the search easier?\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "**BONUS**: If you have time, you can try to replicate (part of) the experiments from Exercise 2, this time using Evolution Strategies (as seen in Lab 3), instead of Genetic Algorithm. Start from Exercise 3 and follow the same steps from Exercise 2, see the cell below.\n",
    "\n",
    "- Do you see any difference in performance between GA and ES? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the ES\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the ES\n",
    "args[\"pop_size\"] = 20  # mu\n",
    "args[\"num_offspring\"] = 100  # lambda\n",
    "args[\"sigma\"] = 1.0  # default standard deviation\n",
    "args[\"strategy_mode\"] = None  # es.GLOBAL, es.INDIVIDUAL\n",
    "args[\"mixing_number\"] = 1  # rho\n",
    "args[\"use_penalty\"] = False\n",
    "\n",
    "args[\"problem_class\"] = cb.Simionescu\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = f\"ES - {args['problem_class'].__name__}\"\n",
    "\n",
    "seed = None\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the ES\n",
    "best_individual, best_fitness, final_pop = run_es(\n",
    "    rng, num_vars=2, display=display, use_log_scale=True, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the ES\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the ES\n",
    "args[\"pop_size\"] = 20  # mu\n",
    "args[\"num_offspring\"] = 100  # lambda\n",
    "args[\"sigma\"] = 1.0  # default standard deviation\n",
    "args[\"strategy_mode\"] = None  # es.GLOBAL, es.INDIVIDUAL\n",
    "args[\"mixing_number\"] = 1  # rho\n",
    "args[\"use_penalty\"] = True\n",
    "\n",
    "args[\"problem_class\"] = cb.Simionescu\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = f\"ES - {args['problem_class'].__name__}\"\n",
    "\n",
    "seed = None\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the ES\n",
    "best_individual, best_fitness, final_pop = run_es(\n",
    "    rng, num_vars=2, display=display, use_log_scale=True, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the ES\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the ES\n",
    "args[\"pop_size\"] = 20  # mu\n",
    "args[\"num_offspring\"] = 100  # lambda\n",
    "args[\"sigma\"] = 1.0  # default standard deviation\n",
    "args[\"strategy_mode\"] = None  # es.GLOBAL, es.INDIVIDUAL\n",
    "args[\"mixing_number\"] = 1  # rho\n",
    "args[\"use_penalty\"] = True\n",
    "\n",
    "args[\"problem_class\"] = cb.SphereCircle\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = f\"ES - {args['problem_class'].__name__}\"\n",
    "\n",
    "seed = None\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the ES\n",
    "best_individual, best_fitness, final_pop = run_es(\n",
    "    rng, num_vars=2, display=display, use_log_scale=True, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "# print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the ES\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the ES\n",
    "args[\"pop_size\"] = 20  # mu\n",
    "args[\"num_offspring\"] = 100  # lambda\n",
    "args[\"sigma\"] = 2.0  # default standard deviation\n",
    "args[\"strategy_mode\"] = None  # es.GLOBAL, es.INDIVIDUAL\n",
    "args[\"mixing_number\"] = 1  # rho\n",
    "args[\"use_penalty\"] = True\n",
    "args[\"bounder\"] = ec.Bounder([-10, 10], [-10, 10])\n",
    "\n",
    "args[\"problem_class\"] = cb.SphereCircle\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = f\"ES - {args['problem_class'].__name__}\"\n",
    "\n",
    "seed = None\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the ES\n",
    "best_individual, best_fitness, final_pop = run_es(\n",
    "    rng, num_vars=2, display=display, use_log_scale=True, maximize=True, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "function = args[\"problem_class\"](2)\n",
    "# print(\"Minimum: \", function.global_optimum)\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function.printSolution(best_individual)  # type: ignore\n",
    "\n",
    "plot_final_pop(function, final_pop, bounds=((11, -11), (11, -11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "## Exercise 1\n",
    "See exercise 3 of previous report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Here we analyze the behaviour of GA an constrained optimization problems\n",
    "\n",
    "#### RosenbrockCubicLine\n",
    "We can see that the results are similar regardless of the use of a penalty for unfeasible solution which implies that the majority of the individuals never leave the feasible region.\n",
    "\n",
    "Non-penalized\n",
    "\n",
    "![RosenbrockCubicLine](img/ex2_rosenbrock_heat_unconstrained.png) ![RosenbrockCubicLine](img/ex2_rosenbrock_pop_unconstrained.png)\n",
    "\n",
    "Penalized\n",
    "\n",
    "![RosenbrockCubicLine](img/ex2_rosenbrock_heat_constrained.png) ![RosenbrockCubicLine](img/ex2_rosenbrock_pop_constrained.png)\n",
    "\n",
    "#### Simonescu \n",
    "On the other hand in the case of the Simonescu function we can see that the penalized version is able to better find the optimum. This is probably due to the fact that the minimum lies close to the border of the feasible region so when the penalty is appliede the individuals are pushed near the border.Moreover, the heatmap for the penalized version shows a easier fitness landscape to navigate.\n",
    "\n",
    "Non-penalized\n",
    "\n",
    "![Simonescu](img/ex2_simonescu_heat_unconstrained.png) ![Simonescu](img/ex2_simonescu_pop_unconstrained.png)\n",
    "\n",
    "Penalized\n",
    "\n",
    "![Simonescu](img/ex2_simonescu_heat_constrained.png) ![Simonescu](img/ex2_simonescu_pop_constrained.png)\n",
    "\n",
    "We can also see the results using ES which are able to find the optimum in both cases.\n",
    "\n",
    "![Simonescu](img/ex2_simonescu_heat_unconstrained_es.png) ![Simonescu](img/ex2_simonescu_pop_unconstrained_es.png)\n",
    "\n",
    "![Simonescu](img/ex2_simonescu_heat_constrained_es.png) ![Simonescu](img/ex2_simonescu_pop_constrained_es.png)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### SphereCircle\n",
    "\n",
    "In the case of the SphereCircle we want to maximize the fitness function with the additional constraint that the solution must lie inside the unit cicle which implies that the optimum lies on the border of the feasible region. We compare the results with different sized search spaces. For the larger search space we can see how we have two very distinct populations, one on the border of the feasible region while the other on the border of the search space. This may be due to the fact that the penalty is not strong enough to push the individuals towards the border of the feasible region so they move towards the area with the highest fitness.\n",
    "\n",
    "![SphereCircle](img/ex2_circle_heat.png) ![SphereCircle](img/ex2_circle_pop.png)\n",
    "\n",
    "![SphereCircle](img/ex2_circle_10_heat.png) ![SphereCircle](img/ex2_circle_10_pop.png)\n",
    "\n",
    "Using ES we can see how the majority of the individuals lie on the border of the feasible region.\n",
    "\n",
    "![SphereCircle](img/ex2_circle_es_heat.png) ![SphereCircle](img/ex2_circle_es_pop.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
