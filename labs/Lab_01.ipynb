{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Goal.\n",
    "The goal of this lab is to perform some preliminary experiments aimed at understanding some advantages and pitfalls of Evolutionary Algorithms (EAs). In particular, you will observe the effects of mutations and problem dimensionality, and reflect to what extent these observations also apply to biological evolution.\n",
    "\n",
    "Note that, unless otherwise specified, in this module's exercises we will use real-valued genotypes. \n",
    "I.e., an individual is a vector of real-valued parameters $\\mathbf{x} = \\{x_1, x_2, \\dots, x_N\\}$ (however, keep in mind that other types of individual representations are possible, such as trees or bit strings, which will not be explored in this lab). The fitness of an individual is given by the fitness function $f(\\mathbf{x})$. The aim of the algorithms will be to *minimize* the fitness function $f(\\mathbf{x})$, i.e. to find the vector $\\mathbf{x}_{min}$ that has the lowest value $f(\\mathbf{x})$. In other words, lower values $f(\\mathbf{x})$ correspond to a better fitness!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Exercise 1\n",
    "In this first exercise, we will not yet run a complete EA. Instead, we consider a single parent individual **$x_{0}$**, from which a number of offspring individuals are created using a Gaussian mutation operator (perturbe a point locally according to a Gaussain) (which adds a random number from a Gaussian distribution with mean zero and standard deviation $\\sigma$ to each parameter $x_i$ of the parent). The fitness function, shown in the figure below for $N=2$ variables, is defined as:\n",
    " \n",
    "$f(\\mathbf{x}) = \\sum_{i=1}^{N}{x^2_i}$\n",
    "\n",
    "![sphere.png](img/img_01/sphere.png)\n",
    "\n",
    "This function is usually defined to as *sphere* function $^{[1]}$ and is one of the most used benchmark functions in continuous (real-valued) optimization. This fitness function is unimodal, i.e. it has a single global minimum at the origin. Furthermore, this function is *scalable*, i.e. it can be defined for any arbitrary number of variables ($N=1, 2, 3, ...$, i.e. $N \\in \\mathbb{N}$).\n",
    "We will analyze the effects of mutations on the fitness depending on the value of the parent $\\mathbf{x}_0$, the mutation magnitude $^{[2]}$ (the standard deviation $\\sigma$), and the number of dimensions $N$ of the search space.\n",
    "\n",
    "To start the experiments, run the next cell $^{[3]}$. It willl generate offspring from a single parent $\\mathbf{x}_0$ using a Gaussian mutation operator (which adds a random number from a Gaussian distribution with mean zero and standard deviation $\\sigma$ to the parent). Generate offspring from different parents (e.g. $\\mathbf{x}_0$=0.1, 1, 10) using different mutation magnitudes (standard deviations $\\sigma$). First consider the one-dimensional case, then two dimensions, and finally many dimensions (e.g. $N =100$). For one or two dimensions, the fitness landscape with the parent and the offspring is shown. For more dimensions, a __[boxplot](http://matplotlib.org/api/pyplot_api.html\\#matplotlib.pyplot.boxplot)__ if you are unfamiliar with boxplots with the fitness of the offspring is shown where the green, dashed line is the fitness of the parent (we want our perturbations to have a smaller fitness value than the parent).\n",
    "\n",
    "Try to answer the following questions:\n",
    "\n",
    "- Do the mutations tend to improve or worsen the fitness of the parent?\n",
    "- Are low or high mutation magnitudes best for improving the fitness? How does this depend on the initial value of the parent and on the number of dimensions of the search space?\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "[1]: \n",
    "Note that its contour lines, i.e. the loci of points for which the function has a constant value, are $N$-dimensional *spheres* centered in **0**. For instance, in 2-D, the contour lines are curves described by $x^2_1+x^2_2=k$, which correspond to a circle (the equivalent of a sphere in 2 dimension) with radius $\\sqrt{k}$ and center in $\\{0,0\\}$. In 3-D, the contour lines are curves described by $x^2_1+x^2_2+x^2_3=k$, which correspond to a sphere with radius $\\sqrt{k}$ and center in $\\{0,0,0\\}$. For $N>3$, each contour line corresponds to a *hyper-sphere*, i.e. a generalization of a sphere.\n",
    "\n",
    "[2]: \n",
    "In the following, *mutation magnitude* indicates a generic measure of the mutation effect on the genotype. E.g. in continuous optimization with Gaussian mutation $x'=x+\\mathcal{N}(0, \\sigma$) the *mutation magnitude* is simply $\\sigma$. This is different from the *mutation probability*, that is the chance that a given loci would be mutated. The combination of these two aspects, magnitude and probability, may be considered the overall *mutation rate*.] \n",
    "\n",
    "[3]: \n",
    "For all the exercises in this lab you may set the seed for the pseudo-random number generator. This will allow you to reproduce your results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_01.ga import generate_offspring\n",
    "from random import Random\n",
    "from scipy.stats import ttest_1samp\n",
    "from matplotlib.pyplot import figure, show\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\n",
    "Choose the parent x0 that will be mutated. It can have an arbitrary \n",
    "number of dimensions, but plotting of the fitness landscape is only \n",
    "possible for the 1D or 2D case.\n",
    "\"\"\"\n",
    "\n",
    "x0 = [10]  # 1 parameter\n",
    "# x0 = [10, 10]; # 2 parameters\n",
    "# x0 = 10*ones(50); # 50 parameters\n",
    "\n",
    "# Set the standard deviation of the Gaussian mutations\n",
    "std_dev = 1\n",
    "\n",
    "# Set number of offspring to be generated\n",
    "num_offspring = 1000\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "args = {}\n",
    "args[\"fig_title\"] = \"Random sampling\"\n",
    "\n",
    "seed = 100\n",
    "rng = Random(seed)\n",
    "plot_fitness_landscape = True  # Set to False to disable the plots\n",
    "parent_fitness, offspring_fitnesses = generate_offspring(\n",
    "    rng, x0, std_dev, num_offspring, plot_fitness_landscape, args\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Boxplot of the offspring fitnesses. The fitness of the parent is plotted as\n",
    "a dashed, green line.\n",
    "\"\"\"\n",
    "fig = figure(\"Offspring fitness\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot(offspring_fitnesses)\n",
    "ax.set_xticklabels([])\n",
    "ax.plot([0, 2], [parent_fitness, parent_fitness], \"g--\", label=\"Parent fitness\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.legend()\n",
    "show()\n",
    "\n",
    "print(parent_fitness)\n",
    "print(ttest_1samp(offspring_fitnesses, popmean=parent_fitness))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "In this exercise we will try to confirm the observations that we did qualitatively in the previous exercise, by plotting boxplots side-by-side to evaluate the statistical significance of observed differences.\n",
    "\n",
    "Run the next cell, and compare different values for:\n",
    "\n",
    "- the number of dimensions of the search space;\n",
    "- the value of the parent (how close the starting point is to the optimum);\n",
    "- the mutation magnitude $\\sigma$ (smaller $\\sigma$ gives on average smaller mutations from the parent);\n",
    "\n",
    "and try to confirm the answers that you gave in the previous exercise. See the comments in the script for more details.\n",
    "\n",
    "**NOTE**: If you vary one of these three parameters, *make sure that you set the other two at a constant value* (otherwise it may be difficult to interpret your results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_01.ga import generate_offspring\n",
    "from pylab import *\n",
    "from random import Random\n",
    "import sys\n",
    "\n",
    "\"\"\" \n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\n",
    "Try different values for either:\n",
    "    (1) the number of dimensions of the search space\n",
    "    (2) how close the parent is to the global optimum\n",
    "    (3) the mutation rate\n",
    " If you vary one of the three things, you may want to keep the other two\n",
    " at a constant value to better understand the effects (as shown in the\n",
    " example below).\n",
    "\"\"\"\n",
    "\n",
    "# Number of dimensions\n",
    "num_vars_1 = 2\n",
    "num_vars_2 = 2\n",
    "num_vars_3 = 2\n",
    "# How close the parent is to the minimum\n",
    "value_1 = 1\n",
    "value_2 = 10\n",
    "value_3 = 20\n",
    "# Value of the parent\n",
    "x0_1 = value_1 * ones(num_vars_1)\n",
    "x0_2 = value_2 * ones(num_vars_2)\n",
    "x0_3 = value_3 * ones(num_vars_3)\n",
    "# standard deviation of the mutation\n",
    "std_dev_1 = 2\n",
    "std_dev_2 = 2\n",
    "std_dev_3 = 2\n",
    "# Number of offspring to be generated\n",
    "num_offspring = 200\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "args = {}\n",
    "seed = 100\n",
    "rng = Random(seed)\n",
    "# Generate offspring for the three conditions\n",
    "args[\"fig_title\"] = \"Random sampling (condition 1)\"\n",
    "parent_fitness_1, offspring_fitness_1 = generate_offspring(\n",
    "    rng, x0_1, std_dev_1, num_offspring, False, args\n",
    ")\n",
    "args[\"fig_title\"] = \"Random sampling (condition 2)\"\n",
    "parent_fitness_2, offspring_fitness_2 = generate_offspring(\n",
    "    rng, x0_2, std_dev_2, num_offspring, False, args\n",
    ")\n",
    "args[\"fig_title\"] = \"Random sampling (condition 3)\"\n",
    "parent_fitness_3, offspring_fitness_3 = generate_offspring(\n",
    "    rng, x0_3, std_dev_3, num_offspring, False, args\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Boxplot of the offspring fitnesses. The fitness of the parent is plotted as\n",
    "a dashed, green line.\n",
    "\"\"\"\n",
    "fig = figure(\"Offspring fitness\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot([offspring_fitness_1, offspring_fitness_2, offspring_fitness_3], notch=False)\n",
    "ax.plot([0.5, 1.5], [parent_fitness_1, parent_fitness_1], \"g--\", label=\"Parent fitness\")\n",
    "ax.plot([1.5, 2.5], [parent_fitness_2, parent_fitness_2], \"g--\")\n",
    "ax.plot([2.5, 3.5], [parent_fitness_3, parent_fitness_3], \"g--\")\n",
    "ax.set_xticklabels([\"1\", \"2\", \"3\"])\n",
    "ax.set_xlabel(\"Condition\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.legend()\n",
    "show()\n",
    "\n",
    "print(\"mean for condition 1\", mean(offspring_fitness_1))\n",
    "print(\"mean for condition 2\", mean(offspring_fitness_2))\n",
    "print(\"mean for condition 3\", mean(offspring_fitness_3))\n",
    "print(\n",
    "    \"t test for condition 1\", ttest_1samp(offspring_fitness_1, popmean=parent_fitness_1)\n",
    ")\n",
    "print(\n",
    "    \"t test for condition 2\", ttest_1samp(offspring_fitness_2, popmean=parent_fitness_2)\n",
    ")\n",
    "print(\n",
    "    \"t test for condition 3\", ttest_1samp(offspring_fitness_3, popmean=parent_fitness_3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "We will now use an EA to find the minimum of the unimodal fitness function defined in the previous exercise and analyze the effect of the mutation magnitude and the dimensionality of the search space on the results.\n",
    "\n",
    "Run the next cell to run a basic, mutation-only EA on the 1-D sphere function first.\n",
    "\n",
    "- How close is the best individual from the global optimum? \n",
    "\n",
    "Increase the dimensionality of the search space to two and more.\n",
    "\n",
    "- How close are the best individuals now from the global optimum?\n",
    "- Can you get as close as in the one-dimensional case by modifying the mutation magnitude and/or the number of generations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from random import Random\n",
    "from utils.utils_01.ga import run_ga\n",
    "import sys\n",
    "\n",
    "\"\"\"    \n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "num_vars = 1  # Number of dimensions of the search space\n",
    "std_dev = 1  # Standard deviation of the Gaussian mutations\n",
    "max_generations = 100  # Number of generations of the GA\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 1.0  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = 100\n",
    "rng = Random(seed)\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = run_ga(\n",
    "    rng,\n",
    "    num_vars=num_vars,\n",
    "    max_generations=max_generations,\n",
    "    display=display,\n",
    "    gaussian_stdev=std_dev,\n",
    "    **args,\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "# The distance from the optimum in the N-dimensional space\n",
    "print(\"Distance from Global Optimum\", sqrt(sum(array(best_individual) ** 2)))\n",
    "if display:\n",
    "    ioff()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "In this exercise we will try to confirm the observations that we did qualitatively in the previous exercise, by plotting boxplots side-by-side to evaluate the statistical significance of observed differences.\n",
    "\n",
    "Run the next cell to do three batches of $30$ runs of the EA with different mutation magnitudes (it may take a minute). The boxplot compares the best fitness values obtained (at the end of each run) in the three conditions.\n",
    "\n",
    "- Did you see any difference in the best fitness obtained? Try to explain the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from random import Random\n",
    "from utils.utils_01.ga import run_ga\n",
    "import sys\n",
    "\n",
    "\"\"\"    \n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "num_vars = 2  # Number of dimensions of the search space\n",
    "std_devs = [0.01, 0.1, 1.0]  # Standard deviation of the Gaussian mutations\n",
    "max_generations = 50  # Number of generations of the GA\n",
    "num_runs = 30  # Number of runs to be done for each stdev\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"crossover_rate\"] = 0  # Crossover fraction\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"mutation_rate\"] = 1.0  # fraction of loci to perform mutation on\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"pop_init_range\"] = [-10, 10]  # Range for the initial population\n",
    "display = False  # Plot initial and final populations\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = None\n",
    "rng = Random(seed)\n",
    "# run the GA *num_runs* times for each std_dev and record the best fits\n",
    "best_fitnesses = [\n",
    "    [\n",
    "        run_ga(\n",
    "            rng,\n",
    "            num_vars=num_vars,\n",
    "            max_generations=max_generations,\n",
    "            display=display,\n",
    "            gaussian_stdev=std_dev,\n",
    "            **args,\n",
    "        )[1]\n",
    "        for _ in range(num_runs)\n",
    "    ]\n",
    "    for std_dev in std_devs\n",
    "]\n",
    "\n",
    "fig = figure(\"GA (best fitness)\")\n",
    "ax = fig.gca()\n",
    "ax.boxplot(best_fitnesses)\n",
    "ax.set_xticklabels(std_devs)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Std. dev.\")\n",
    "ax.set_ylabel(\"Best fitness\")\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
