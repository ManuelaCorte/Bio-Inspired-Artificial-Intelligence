{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Goal\n",
    "The goal of this lab is to familiarize yourself with some of the constraints handling techniques used in Evolutionary Computation.\n",
    "\n",
    "Note once again that, unless otherwise specified, in this module's exercises we will use real-valued genotypes and that the aim of the algorithms will be to *minimize* the fitness function $f(\\mathbf{x})$, i.e. lower values correspond to a better fitness!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "In this exercise we will continue the investigation of the multiple-disk clutch brake design problem we have seen in the previous lab. In this case, we will consider the full problem including a number of constraints $g_i(x)$, as defined in Figure below. The constraints have been implemented for you in the provided `disk_clutch_brake.py`. Please note that the only difference with respect to the code we have seen in the previous lab is the activation of the constraints, obtained by setting the variable `constrained` to `True` in Exercise 1 (equivalent to Exercise 3 from the previous lab).\n",
    "\n",
    "<img src=\"img/clutch-brake-definition.png\" alt=\"Alternative text\" />\n",
    "\n",
    "When constraints are enforced the notion of constrained-Pareto-domination comes into play. A solution $i$ now is considered to dominate a solution $j$ if any of the following conditions are true:\n",
    "\n",
    "- Solution $i$ is feasible and solution $j$ is not\n",
    "- Solutions $i$ and $j$ are both infeasible, but solution $i$ has a smaller overall constraint violation.\n",
    "- Solutions $i$ and $j$ are feasible and solution $i$ dominates solution $j$\n",
    "\n",
    "As in the previous lab, the final population and fitness values are saved on a file `exercise_1.csv` \\{$r_i$, $r_o$, $t$, $F$, $Z$, $mass$, $time$\\}, one line for each solution in the Pareto front. Also in this case, you may want to try plotting these data in different ways to gain further insights.\n",
    "\n",
    "- How do your results change from the unconstrained version (from the previous lab)?\n",
    "- Do your previous parameters continue to solve the problem?\n",
    "- Try to increase the population size and/or the number of generations to see if you can find better solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from functools import reduce\n",
    "\n",
    "from inspyred.ec import variators\n",
    "\n",
    "# local functions\n",
    "from utils.utils_05.inspyred_utils import NumpyRandomWrapper\n",
    "from utils.utils_05 import multi_objective\n",
    "from utils.utils_05.disk_clutch_brake import DiskClutchBrake, disk_clutch_brake_mutation\n",
    "\n",
    "\"\"\" \n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "display = True\n",
    "\n",
    "# parameters for NSGA-2\n",
    "args = {}\n",
    "args[\"pop_size\"] = 50\n",
    "args[\"max_generations\"] = 250\n",
    "constrained = True\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "problem = DiskClutchBrake(constrained)\n",
    "if constrained:\n",
    "    args[\"constraint_function\"] = problem.constraint_function\n",
    "args[\"objective_1\"] = \"Brake Mass (kg)\"\n",
    "args[\"objective_2\"] = \"Stopping Time (s)\"\n",
    "\n",
    "args[\"variator\"] = [variators.blend_crossover, disk_clutch_brake_mutation]\n",
    "\n",
    "args[\"fig_title\"] = \"NSGA-2\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "final_pop, final_pop_fitnesses = multi_objective.run_nsga2(\n",
    "    rng, problem, display=display, num_vars=5, **args\n",
    ")\n",
    "\n",
    "print(\"Final Population\\n\", final_pop)\n",
    "print()\n",
    "print(\"Final Population Fitnesses\\n\", final_pop_fitnesses)\n",
    "\n",
    "output = open(\"exercise_1.csv\", \"w\")\n",
    "for individual, fitness in zip(final_pop, final_pop_fitnesses):\n",
    "    output.write(reduce(lambda x, y: str(x) + \",\" + str(y), individual))\n",
    "    output.write(\",\")\n",
    "    output.write(reduce(lambda x, y: str(x) + \",\" + str(y), fitness))\n",
    "    output.write(\"\\n\")\n",
    "output.close()\n",
    "\n",
    "ioff()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "In this exercise we will test the Genetic Algorithm we used in Lab 2 for solving a set of constrained optimization benchmark functions. In this case we will consider five benchmark problems from the Wikipedia page on Test functions for constrained optimization (see [link](https://en.wikipedia.org/wiki/Test_functions_for_optimization\\#Test_functions_for_constrained_optimization)), plus an additional sphere function with a constraint. We will limit the experiments only on two dimensions, to visualize the fitness landscape.\n",
    "\n",
    "Try at least one or two of the following benchmark functions:\n",
    "1. RosenbrockCubicLine\n",
    "2. RosenbrockDisk\n",
    "3. MishraBirdConstrained\n",
    "4. Townsend\n",
    "5. Simionescu\n",
    "\n",
    "You can change the problem by changing the parameter `args[problem_class]` in the cello below. By default, the constraints are ignored by the GA. In order to set the GA to handle the constraints, set the variable `usePenalty=True` in `constrained_benchmarks.py`.\n",
    "\n",
    "- Do you see any difference in the GA's behavior (and results) when the penalty is enabled or disabled?\n",
    "- Try to modify the penalty functions used in the code of each benchmark function (check the code corresponding to `if usePenalty`, and/or change the main parameters of the GA `max_generations`, `pop_size`, `gaussian_stdev`, `mutation_rate`, `tournament_size`, `num_elites`) in *Exercise 2*. Are you able to find the optimum on all the benchmark functions you tested?\n",
    "\n",
    "Now, analyze the benchmark `SphereCircle` (look at the code in `constrained_benchmarks.py`). In this case we are *maximizing* the 2-d sphere function we have already seen in the previous labs ($f(x) = x_1^2 + x_2^2$), subject to the constraint:\n",
    "$\n",
    " g_1(x) = x_1^2 + x_2^2 \\leq 1 \\longrightarrow g_1(x) = x_1^2 + x_2^2 - 1 \\leq 0\n",
    "$\n",
    "Here, candidates solutions represent ordered pairs and their fitness is simply their distance from the origin. However, the constraint punishes solutions that lie *outside* the unit circle. Such a scenario should produce an optimum that lies on the unit circle. By default, the code penalizes candidate solutions outside the unit circle by assigning them a fitness value equal to -1.\n",
    "\n",
    "- Is the GA able to find the optimal solution lying on the unit circle? If not, try to change some of the GA's parameters to reach the optimum.\n",
    "- By default, the sphere function is defined in a domain $[-5.12,5.12]$ along each dimension. Try to increase the search space (to do so, change  `self.bounder` and `generator` in the class `SphereCircle`. To progressively increasing boundaries (e.g. $[-10,10]$, $[-20,20]$, etc.). Is the GA still able to explore the feasible region and find the optimum?\n",
    "-  If not, try to think of a way to guide the GA towards the feasible region. How could you change the penalty function to do so? (Hint: look at the `evaluator` method of the class `SphereCircle` and consider that we are maximizing the fitness function, while we want to minimize the violation given by $g_1(x)$.\n",
    "\n",
    "\n",
    "Finally, you can create your own constrained optimization problem by modifying the class template  `SphereConstrained` you will find in `constrained_benchmarks.py`.\n",
    "\n",
    "- Try to modify the sphere function problem by adding one or more linear/non-linear constraints, and analyze how the optimum changes depending on the presence of constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local functions\n",
    "from utils.utils_05.inspyred_utils import NumpyRandomWrapper\n",
    "from utils.utils_05 import constrained_benchmarks\n",
    "from utils.utils_05 import ga\n",
    "from inspyred import ec\n",
    "\n",
    "\n",
    "class SphereConstrained(constrained_benchmarks.ConstrainedBenchmark):\n",
    "    def __init__(self, dimensions=2):\n",
    "        constrained_benchmarks.Benchmark.__init__(self, dimensions)\n",
    "        self.bounder = ec.Bounder([-5.12] * self.dimensions, [5.12] * self.dimensions)\n",
    "        self.maximize = False\n",
    "        self.global_optimum = [0 for _ in range(self.dimensions)]\n",
    "\n",
    "    def generator(self, random, args):\n",
    "        return [random.uniform(-5.12, 5.12) for _ in range(self.dimensions)]\n",
    "\n",
    "    def evaluator(self, candidates, args):\n",
    "        fitness = []\n",
    "        for c in candidates:\n",
    "            f = self.f(c[0], c[1])\n",
    "            usePenalty = True\n",
    "            if usePenalty:\n",
    "                pass  # Change this line to handle penalty function\n",
    "                # penalty function (note that in this case we are minimizing, so we add a positive value)\n",
    "                # g1 = self.g1(c[0],c[1]) # <=0\n",
    "                # g2 = self.g2(c[0],c[1]) # <=0\n",
    "                # ...\n",
    "                # if g1 > 0 or g2 > 0 or ...:\n",
    "                #    f = f + ...\n",
    "            fitness.append(f)\n",
    "        return fitness\n",
    "\n",
    "    def constraintsEvaluator(self, candidates, args):\n",
    "        constraints = []\n",
    "        for c in candidates:\n",
    "            pass\n",
    "            # Change this part to evaluate the constraints\n",
    "            # g1 = self.g1(c[0],c[1]) # <=0\n",
    "            # g2 = self.g2(c[0],c[1]) # <=0\n",
    "            # ...\n",
    "            # constraints.append([g1,g2,...])\n",
    "        return constraints\n",
    "\n",
    "    def f(self, x, y):\n",
    "        return x**2 + y**2\n",
    "\n",
    "    # Implement here some constraints\n",
    "    \"\"\"\n",
    "    def g1(self,x,y):\n",
    "        return ...\n",
    "   \n",
    "    def g1(self,x,y):\n",
    "        return ...\n",
    "    \"\"\"\n",
    "\n",
    "    def printSolution(self, c):\n",
    "        f = self.f(c[0], c[1])\n",
    "        # g1 = self.g1(c[0],c[1])\n",
    "        # g2 = self.g2(c[0],c[1])\n",
    "        print(\"f =\", f)\n",
    "        \"\"\"\n",
    "        print(\"g1 =\", g1)\n",
    "        print(\"g2 =\", g2)\n",
    "        if g1 > 0: or g2 > 0:\n",
    "            print(\"(unfeasible)\")\n",
    "        else:\n",
    "            print(\"(feasible)\")\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "# parameters for the GA\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the GA\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"gaussian_stdev\"] = 0.8  # Standard deviation of the Gaussian mutations\n",
    "args[\"mutation_rate\"] = 0.5  # fraction of loci to perform mutation on\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "\n",
    "# args[\"problem_class\"] = constrained_benchmarks.RosenbrockCubicLine\n",
    "# args[\"problem_class\"] = constrained_benchmarks.RosenbrockDisk\n",
    "# args[\"problem_class\"] = constrained_benchmarks.MishraBirdConstrained\n",
    "args[\"problem_class\"] = constrained_benchmarks.Townsend  # mutation rate 0.8\n",
    "# args[\"problem_class\"] = constrained_benchmarks.Simionescu\n",
    "# args[\"problem_class\"] = constrained_benchmarks.SphereCircle\n",
    "# args[\"problem_class\"] = SphereConstrained\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"GA\"\n",
    "\n",
    "seed = 21\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the GA\n",
    "best_individual, best_fitness, final_pop = ga.run_ga(\n",
    "    rng, num_vars=2, display=display, use_log_scale=False, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function = args[\"problem_class\"](2).printSolution(best_individual)\n",
    "\n",
    "if display:\n",
    "    if args[\"problem_class\"] == constrained_benchmarks.SphereCircle:\n",
    "        x = []\n",
    "        y = []\n",
    "        c = []\n",
    "        final_pop.sort()\n",
    "        num_feasible = len([p for p in final_pop if p.fitness >= 0])\n",
    "        feasible_count = 0\n",
    "        for i, p in enumerate(final_pop):\n",
    "            x.append(p.candidate[0])\n",
    "            y.append(p.candidate[1])\n",
    "            if i == len(final_pop) - 1:\n",
    "                c.append(\"r\")\n",
    "            elif p.fitness < 0:\n",
    "                c.append(\"0.98\")\n",
    "            else:\n",
    "                c.append(str(1 - feasible_count / float(num_feasible)))\n",
    "                feasible_count += 1\n",
    "        angles = linspace(0, 2 * pi, 100)\n",
    "        figure(str(args[\"problem_class\"]))\n",
    "        lower_bound_1 = constrained_benchmarks.SphereCircle(2).bounder.lower_bound[0]\n",
    "        lower_bound_2 = constrained_benchmarks.SphereCircle(2).bounder.lower_bound[1]\n",
    "        upper_bound_1 = constrained_benchmarks.SphereCircle(2).bounder.upper_bound[0]\n",
    "        upper_bound_2 = constrained_benchmarks.SphereCircle(2).bounder.upper_bound[1]\n",
    "        plot(cos(angles), sin(angles), color=\"b\")\n",
    "        xlim(lower_bound_1, upper_bound_1)\n",
    "        ylim(lower_bound_2, upper_bound_2)\n",
    "        axes().set_aspect(\"equal\")\n",
    "        scatter(x, y, color=c)\n",
    "\n",
    "    ioff()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Instructions and questions\n",
    "\n",
    "Concisely note down your observations from the previous exercises (follow the bullet points) and think about the following questions. \n",
    "\n",
    "- What do you think is the most efficient way to handle constraints in EAs?\n",
    "- Do you think that the presence of constraints makes the search *always* more difficult? Can you think of cases in which the constraints could actually make the search easier?\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "**BONUS**: If you have time, you can try to replicate (part of) the experiments from Exercise 2, this time using Evolution Strategies (as seen in Lab 3), instead of Genetic Algorithm. Start from Exercise 3 and follow the same steps from Exercise 2, see the cell below.\n",
    "\n",
    "- Do you see any difference in performance between GA and ES? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local functions\n",
    "from utils.utils_05.inspyred_utils import NumpyRandomWrapper\n",
    "from utils.utils_05 import constrained_benchmarks\n",
    "from utils.utils_05 import es\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "Edit this part to do the exercises\n",
    "\"\"\"\n",
    "\n",
    "# parameters for the ES\n",
    "args = {}\n",
    "args[\"max_generations\"] = 100  # Number of generations of the ES\n",
    "args[\"pop_size\"] = 20  # mu\n",
    "args[\"num_offspring\"] = 100  # lambda\n",
    "args[\"sigma\"] = 1.0  # default standard deviation\n",
    "args[\"strategy_mode\"] = None  # es.GLOBAL, es.INDIVIDUAL\n",
    "args[\"mixing_number\"] = 1  # rho\n",
    "\n",
    "# args[\"problem_class\"] = constrained_benchmarks.RosenbrockCubicLine\n",
    "# args[\"problem_class\"] = constrained_benchmarks.RosenbrockDisk\n",
    "# args[\"problem_class\"] = constrained_benchmarks.MishraBirdConstrained\n",
    "# args[\"problem_class\"] = constrained_benchmarks.Townsend\n",
    "# args[\"problem_class\"] = constrained_benchmarks.Simionescu\n",
    "args[\"problem_class\"] = constrained_benchmarks.SphereCircle\n",
    "# args[\"problem_class\"] = constrained_benchmarks.SphereConstrained\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "display = True  # Plot initial and final populations\n",
    "\n",
    "args[\"fig_title\"] = \"ES\"\n",
    "\n",
    "seed = None\n",
    "rng = NumpyRandomWrapper(seed)\n",
    "\n",
    "# Run the ES\n",
    "best_individual, best_fitness, final_pop = es.run_es(\n",
    "    rng, num_vars=2, display=display, use_log_scale=True, **args\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_fitness)\n",
    "\n",
    "function = args[\"problem_class\"](2).printSolution(best_individual)\n",
    "\n",
    "if display:\n",
    "    if args[\"problem_class\"] == constrained_benchmarks.SphereCircle:\n",
    "        x = []\n",
    "        y = []\n",
    "        c = []\n",
    "        final_pop.sort()\n",
    "        num_feasible = len([p for p in final_pop if p.fitness >= 0])\n",
    "        feasible_count = 0\n",
    "        for i, p in enumerate(final_pop):\n",
    "            x.append(p.candidate[0])\n",
    "            y.append(p.candidate[1])\n",
    "            if i == len(final_pop) - 1:\n",
    "                c.append(\"r\")\n",
    "            elif p.fitness < 0:\n",
    "                c.append(\"0.98\")\n",
    "            else:\n",
    "                c.append(str(1 - feasible_count / float(num_feasible)))\n",
    "                feasible_count += 1\n",
    "        angles = linspace(0, 2 * pi, 100)\n",
    "        figure(str(args[\"problem_class\"]))\n",
    "        lower_bound_1 = constrained_benchmarks.SphereCircle(2).bounder.lower_bound[0]\n",
    "        lower_bound_2 = constrained_benchmarks.SphereCircle(2).bounder.lower_bound[1]\n",
    "        upper_bound_1 = constrained_benchmarks.SphereCircle(2).bounder.upper_bound[0]\n",
    "        upper_bound_2 = constrained_benchmarks.SphereCircle(2).bounder.upper_bound[1]\n",
    "        plot(cos(angles), sin(angles), color=\"b\")\n",
    "        xlim(lower_bound_1, upper_bound_1)\n",
    "        ylim(lower_bound_2, upper_bound_2)\n",
    "        axes().set_aspect(\"equal\")\n",
    "        scatter(x, y, color=c)\n",
    "\n",
    "    ioff()\n",
    "    show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
